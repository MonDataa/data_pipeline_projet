[2022-12-30T09:08:53.104+0100] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: spark_airflow_project.spark_job_process manual__2022-12-30T08:08:23.361584+00:00 [queued]>
[2022-12-30T09:08:53.185+0100] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: spark_airflow_project.spark_job_process manual__2022-12-30T08:08:23.361584+00:00 [queued]>
[2022-12-30T09:08:53.190+0100] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2022-12-30T09:08:53.191+0100] {taskinstance.py:1284} INFO - Starting attempt 1 of 4
[2022-12-30T09:08:53.191+0100] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2022-12-30T09:08:53.302+0100] {taskinstance.py:1304} INFO - Executing <Task(SparkSubmitOperator): spark_job_process> on 2022-12-30 08:08:23.361584+00:00
[2022-12-30T09:08:53.306+0100] {standard_task_runner.py:55} INFO - Started process 16347 to run task
[2022-12-30T09:08:53.337+0100] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'spark_airflow_project', 'spark_job_process', 'manual__2022-12-30T08:08:23.361584+00:00', '--job-id', '84', '--raw', '--subdir', 'DAGS_FOLDER/spark_airflow.py', '--cfg-path', '/tmp/tmp5r9h4rv1']
[2022-12-30T09:08:53.342+0100] {standard_task_runner.py:83} INFO - Job 84: Subtask spark_job_process
[2022-12-30T09:08:53.461+0100] {task_command.py:389} INFO - Running <TaskInstance: spark_airflow_project.spark_job_process manual__2022-12-30T08:08:23.361584+00:00 [running]> on host momo-VirtualBox
[2022-12-30T09:08:53.630+0100] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Ranga
AIRFLOW_CTX_DAG_ID=spark_airflow_project
AIRFLOW_CTX_TASK_ID=spark_job_process
AIRFLOW_CTX_EXECUTION_DATE=2022-12-30T08:08:23.361584+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-12-30T08:08:23.361584+00:00
[2022-12-30T09:08:53.641+0100] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2022-12-30T09:08:53.642+0100] {spark_submit.py:344} INFO - Spark-Submit cmd: spark-submit --master spark://momo-VirtualBox:7077 --name arrow-spark --queue root.default /home/momo/Bureau/spark_d2.py
[2022-12-30T09:08:56.374+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:56 WARN Utils: Your hostname, momo-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
[2022-12-30T09:08:56.376+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2022-12-30T09:08:57.260+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO SparkContext: Running Spark version 3.3.1
[2022-12-30T09:08:57.340+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2022-12-30T09:08:57.460+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO ResourceUtils: ==============================================================
[2022-12-30T09:08:57.460+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO ResourceUtils: No custom resources configured for spark.driver.
[2022-12-30T09:08:57.462+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO ResourceUtils: ==============================================================
[2022-12-30T09:08:57.463+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO SparkContext: Submitted application: conf pro spark
[2022-12-30T09:08:57.493+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2022-12-30T09:08:57.507+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO ResourceProfile: Limiting resource is cpu
[2022-12-30T09:08:57.508+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2022-12-30T09:08:57.568+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO SecurityManager: Changing view acls to: momo
[2022-12-30T09:08:57.569+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO SecurityManager: Changing modify acls to: momo
[2022-12-30T09:08:57.570+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO SecurityManager: Changing view acls groups to:
[2022-12-30T09:08:57.571+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO SecurityManager: Changing modify acls groups to:
[2022-12-30T09:08:57.571+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(momo); groups with view permissions: Set(); users  with modify permissions: Set(momo); groups with modify permissions: Set()
[2022-12-30T09:08:57.867+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO Utils: Successfully started service 'sparkDriver' on port 44639.
[2022-12-30T09:08:57.910+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO SparkEnv: Registering MapOutputTracker
[2022-12-30T09:08:57.951+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO SparkEnv: Registering BlockManagerMaster
[2022-12-30T09:08:57.984+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2022-12-30T09:08:57.987+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2022-12-30T09:08:57.993+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:57 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2022-12-30T09:08:58.021+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-a3498d77-e79f-4dcb-91b4-d8e253947d56
[2022-12-30T09:08:58.048+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2022-12-30T09:08:58.078+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO SparkEnv: Registering OutputCommitCoordinator
[2022-12-30T09:08:58.299+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2022-12-30T09:08:58.401+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO Executor: Starting executor ID driver on host 10.0.2.15
[2022-12-30T09:08:58.407+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2022-12-30T09:08:58.429+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33173.
[2022-12-30T09:08:58.433+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO NettyBlockTransferService: Server created on 10.0.2.15:33173
[2022-12-30T09:08:58.434+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2022-12-30T09:08:58.437+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.2.15, 33173, None)
[2022-12-30T09:08:58.439+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.15:33173 with 434.4 MiB RAM, BlockManagerId(driver, 10.0.2.15, 33173, None)
[2022-12-30T09:08:58.442+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.2.15, 33173, None)
[2022-12-30T09:08:58.443+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.2.15, 33173, None)
[2022-12-30T09:08:58.852+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2022-12-30T09:08:58.863+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:58 INFO SharedState: Warehouse path is 'file:/home/momo/Bureau/spark-warehouse'.
[2022-12-30T09:08:59.643+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:59 INFO InMemoryFileIndex: It took 38 ms to list leaf files for 1 paths.
[2022-12-30T09:08:59.707+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:59 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
[2022-12-30T09:09:02.576+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:02 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:09:02.578+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:02 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
[2022-12-30T09:09:02.581+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:02 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
[2022-12-30T09:09:03.071+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO CodeGenerator: Code generated in 147.647671 ms
[2022-12-30T09:09:03.133+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.6 KiB, free 434.2 MiB)
[2022-12-30T09:09:03.178+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 434.2 MiB)
[2022-12-30T09:09:03.185+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.15:33173 (size: 34.0 KiB, free: 434.4 MiB)
[2022-12-30T09:09:03.190+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:03.201+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:09:03.354+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:03.369+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:03.370+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:03.370+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:09:03.372+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:03.396+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:03.530+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.8 KiB, free 434.2 MiB)
[2022-12-30T09:09:03.536+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.2 MiB)
[2022-12-30T09:09:03.537+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.15:33173 (size: 5.9 KiB, free: 434.4 MiB)
[2022-12-30T09:09:03.542+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:03.559+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:03.560+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2022-12-30T09:09:03.606+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:03.619+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2022-12-30T09:09:03.742+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:09:03.796+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO CodeGenerator: Code generated in 43.018328 ms
[2022-12-30T09:09:03.885+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1749 bytes result sent to driver
[2022-12-30T09:09:03.898+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 298 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:03.902+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2022-12-30T09:09:03.919+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0,500 s
[2022-12-30T09:09:03.927+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:09:03.927+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2022-12-30T09:09:03.930+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0,575435 s
[2022-12-30T09:09:03.965+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:03 INFO CodeGenerator: Code generated in 20.571619 ms
[2022-12-30T09:09:04.017+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:09:04.017+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:09:04.018+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
[2022-12-30T09:09:04.032+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 199.6 KiB, free 434.0 MiB)
[2022-12-30T09:09:04.066+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.9 MiB)
[2022-12-30T09:09:04.072+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.2.15:33173 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:04.075+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:04.076+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:09:04.126+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.2.15:33173 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2022-12-30T09:09:04.206+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:04.208+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:04.208+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:04.208+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:09:04.208+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:04.211+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:04.251+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 25.0 KiB, free 433.9 MiB)
[2022-12-30T09:09:04.253+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 433.9 MiB)
[2022-12-30T09:09:04.254+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.2.15:33173 (size: 11.8 KiB, free: 434.3 MiB)
[2022-12-30T09:09:04.255+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:04.256+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:04.256+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2022-12-30T09:09:04.259+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:04.262+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2022-12-30T09:09:04.298+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:09:04.399+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1780 bytes result sent to driver
[2022-12-30T09:09:04.402+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 143 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:04.403+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0,192 s
[2022-12-30T09:09:04.404+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:09:04.405+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2022-12-30T09:09:04.405+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2022-12-30T09:09:04.407+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0,200122 s
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - root
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- Code du département: string (nullable = true)
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- Libellé du département: string (nullable = true)
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- Code de la circonscription: integer (nullable = true)
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- Libellé de la circonscription: string (nullable = true)
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- Etat saisie: string (nullable = true)
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- Inscrits: integer (nullable = true)
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- Abstentions: integer (nullable = true)
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- % Abs/Ins: double (nullable = true)
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- Votants: integer (nullable = true)
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- % Vot/Ins: double (nullable = true)
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- Blancs: integer (nullable = true)
[2022-12-30T09:09:04.430+0100] {spark_submit.py:495} INFO - |-- % Blancs/Ins: double (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- % Blancs/Vot: double (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- Nuls: integer (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- % Nuls/Ins: double (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- % Nuls/Vot: double (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- Exprimés: integer (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- % Exp/Ins: double (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- % Exp/Vot: double (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- N°Panneau: integer (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- Sexe: string (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- Nom: string (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- Prénom: string (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- Voix: integer (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- % Voix/Ins: double (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - |-- % Voix/Exp: double (nullable = true)
[2022-12-30T09:09:04.431+0100] {spark_submit.py:495} INFO - 
[2022-12-30T09:09:04.512+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:09:04.512+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:09:04.514+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T09:09:04.532+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2022-12-30T09:09:04.707+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO CodeGenerator: Code generated in 78.950802 ms
[2022-12-30T09:09:04.715+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 199.4 KiB, free 433.7 MiB)
[2022-12-30T09:09:04.735+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.7 MiB)
[2022-12-30T09:09:04.737+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.2.15:33173 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:04.737+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO SparkContext: Created broadcast 4 from showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:04.742+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:09:04.755+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:04.756+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:04.756+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:04.757+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:09:04.757+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:04.759+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:04.769+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 27.1 KiB, free 433.7 MiB)
[2022-12-30T09:09:04.770+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 433.6 MiB)
[2022-12-30T09:09:04.771+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.2.15:33173 (size: 9.9 KiB, free: 434.3 MiB)
[2022-12-30T09:09:04.772+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:04.773+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:04.774+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2022-12-30T09:09:04.775+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:04.777+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
[2022-12-30T09:09:04.790+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:09:04.872+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO CodeGenerator: Code generated in 53.530296 ms
[2022-12-30T09:09:04.936+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.2.15:33173 in memory (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:04.951+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 4556 bytes result sent to driver
[2022-12-30T09:09:04.954+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 179 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:04.958+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 0,196 s
[2022-12-30T09:09:04.959+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:09:04.959+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2022-12-30T09:09:04.964+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2022-12-30T09:09:04.964+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0,204918 s
[2022-12-30T09:09:04.985+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:04 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.2.15:33173 in memory (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:05.004+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.2.15:33173 in memory (size: 11.8 KiB, free: 434.4 MiB)
[2022-12-30T09:09:05.076+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO CodeGenerator: Code generated in 93.988975 ms
[2022-12-30T09:09:05.105+0100] {spark_submit.py:495} INFO - +-------------------+----------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:09:05.105+0100] {spark_submit.py:495} INFO - |Code du département|Libellé du département|Code de la circonscription|Libellé de la circonscription|Etat saisie|Inscrits|Abstentions|% Abs/Ins|Votants|% Vot/Ins|Blancs|% Blancs/Ins|% Blancs/Vot|Nuls|% Nuls/Ins|% Nuls/Vot|Exprimés|% Exp/Ins|% Exp/Vot|N°Panneau|Sexe|    Nom|  Prénom|Voix|% Voix/Ins|% Voix/Exp|
[2022-12-30T09:09:05.105+0100] {spark_submit.py:495} INFO - +-------------------+----------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:09:05.105+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         1|         1ère circonscription|    Complet|   85723|      18592|    21.69|  67131|    78.31|  1154|        1.35|        1.72| 393|      0.46|      0.59|   65584|    76.51|     97.7|        1|   F|ARTHAUD|Nathalie| 317|      0.37|      0.48|
[2022-12-30T09:09:05.105+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         2|         2ème circonscription|    Complet|   99383|      19917|    20.04|  79466|    79.96|  1367|        1.38|        1.72| 352|      0.35|      0.44|   77747|    78.23|    97.84|        1|   F|ARTHAUD|Nathalie| 354|      0.36|      0.46|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         3|         3ème circonscription|    Complet|   81500|      20440|    25.08|  61060|    74.92|   851|        1.04|        1.39| 290|      0.36|      0.47|   59919|    73.52|    98.13|        1|   F|ARTHAUD|Nathalie| 275|      0.34|      0.46|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         4|         4ème circonscription|    Complet|   94359|      19826|    21.01|  74533|    78.99|  1299|        1.38|        1.74| 474|       0.5|      0.64|   72760|    77.11|    97.62|        1|   F|ARTHAUD|Nathalie| 376|       0.4|      0.52|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         5|         5ème circonscription|    Complet|   77144|      18766|    24.33|  58378|    75.67|   970|        1.26|        1.66| 394|      0.51|      0.67|   57014|    73.91|    97.66|        1|   F|ARTHAUD|Nathalie| 336|      0.44|      0.59|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         1|         1ère circonscription|    Complet|   72206|      18597|    25.76|  53609|    74.24|   740|        1.02|        1.38| 404|      0.56|      0.75|   52465|    72.66|    97.87|        1|   F|ARTHAUD|Nathalie| 410|      0.57|      0.78|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         2|         2ème circonscription|    Complet|   73111|      20530|    28.08|  52581|    71.92|   772|        1.06|        1.47| 403|      0.55|      0.77|   51406|    70.31|    97.77|        1|   F|ARTHAUD|Nathalie| 372|      0.51|      0.72|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         3|         3ème circonscription|    Complet|   66580|      17358|    26.07|  49222|    73.93|   699|        1.05|        1.42| 398|       0.6|      0.81|   48125|    72.28|    97.77|        1|   F|ARTHAUD|Nathalie| 358|      0.54|      0.74|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         4|         4ème circonscription|    Complet|   78699|      22961|    29.18|  55738|    70.82|   681|        0.87|        1.22|1143|      1.45|      2.05|   53914|    68.51|    96.73|        1|   F|ARTHAUD|Nathalie| 391|       0.5|      0.73|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         5|         5ème circonscription|    Complet|   82948|      21643|    26.09|  61305|    73.91|   875|        1.05|        1.43| 480|      0.58|      0.78|   59950|    72.27|    97.79|        1|   F|ARTHAUD|Nathalie| 507|      0.61|      0.85|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 03|                Allier|                         1|         1ère circonscription|    Complet|   89193|      20597|    23.09|  68596|    76.91|  1330|        1.49|        1.94| 599|      0.67|      0.87|   66667|    74.74|    97.19|        1|   F|ARTHAUD|Nathalie| 528|      0.59|      0.79|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 03|                Allier|                         2|         2ème circonscription|    Complet|   80780|      19459|    24.09|  61321|    75.91|  1207|        1.49|        1.97| 649|       0.8|      1.06|   59465|    73.61|    96.97|        1|   F|ARTHAUD|Nathalie| 446|      0.55|      0.75|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 03|                Allier|                         3|         3ème circonscription|    Complet|   80018|      18441|    23.05|  61577|    76.95|  1212|        1.51|        1.97| 542|      0.68|      0.88|   59823|    74.76|    97.15|        1|   F|ARTHAUD|Nathalie| 385|      0.48|      0.64|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 04|  Alpes-de-Haute-Pr...|                         1|         1ère circonscription|    Complet|   61692|      13750|    22.29|  47942|    77.71|   691|        1.12|        1.44| 315|      0.51|      0.66|   46936|    76.08|     97.9|        1|   F|ARTHAUD|Nathalie| 275|      0.45|      0.59|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 04|  Alpes-de-Haute-Pr...|                         2|         2ème circonscription|    Complet|   66383|      15540|    23.41|  50843|    76.59|   787|        1.19|        1.55| 309|      0.47|      0.61|   49747|    74.94|    97.84|        1|   F|ARTHAUD|Nathalie| 230|      0.35|      0.46|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 05|          Hautes-Alpes|                         1|         1ère circonscription|    Complet|   59486|      13601|    22.86|  45885|    77.14|   731|        1.23|        1.59| 287|      0.48|      0.63|   44867|    75.42|    97.78|        1|   F|ARTHAUD|Nathalie| 234|      0.39|      0.52|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 05|          Hautes-Alpes|                         2|         2ème circonscription|    Complet|   54033|      11756|    21.76|  42277|    78.24|   664|        1.23|        1.57| 245|      0.45|      0.58|   41368|    76.56|    97.85|        1|   F|ARTHAUD|Nathalie| 194|      0.36|      0.47|
[2022-12-30T09:09:05.106+0100] {spark_submit.py:495} INFO - |                 06|       Alpes-Maritimes|                         1|         1ère circonscription|    Complet|   81800|      24731|    30.23|  57069|    69.77|   603|        0.74|        1.06| 354|      0.43|      0.62|   56112|     68.6|    98.32|        1|   F|ARTHAUD|Nathalie| 166|       0.2|       0.3|
[2022-12-30T09:09:05.107+0100] {spark_submit.py:495} INFO - |                 06|       Alpes-Maritimes|                         2|         2ème circonscription|    Complet|   88918|      22495|     25.3|  66423|     74.7|   949|        1.07|        1.43| 341|      0.38|      0.51|   65133|    73.25|    98.06|        1|   F|ARTHAUD|Nathalie| 216|      0.24|      0.33|
[2022-12-30T09:09:05.107+0100] {spark_submit.py:495} INFO - |                 06|       Alpes-Maritimes|                         3|         3ème circonscription|    Complet|   90956|      26607|    29.25|  64349|    70.75|   789|        0.87|        1.23| 342|      0.38|      0.53|   63218|     69.5|    98.24|        1|   F|ARTHAUD|Nathalie| 206|      0.23|      0.33|
[2022-12-30T09:09:05.107+0100] {spark_submit.py:495} INFO - +-------------------+----------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:09:05.107+0100] {spark_submit.py:495} INFO - only showing top 20 rows
[2022-12-30T09:09:05.107+0100] {spark_submit.py:495} INFO - 
[2022-12-30T09:09:05.292+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:09:05.293+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:09:05.294+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T09:09:05.453+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:09:05.533+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO CodeGenerator: Code generated in 46.03101 ms
[2022-12-30T09:09:05.536+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 199.4 KiB, free 433.9 MiB)
[2022-12-30T09:09:05.545+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.9 MiB)
[2022-12-30T09:09:05.546+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.2.15:33173 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:05.547+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:05.557+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:09:05.591+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2022-12-30T09:09:05.593+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:05.593+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:05.594+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:09:05.596+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:05.599+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:05.611+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 57.4 KiB, free 433.9 MiB)
[2022-12-30T09:09:05.613+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 433.8 MiB)
[2022-12-30T09:09:05.614+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.2.15:33173 (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:05.615+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:05.616+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:05.617+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2022-12-30T09:09:05.619+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:05.622+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
[2022-12-30T09:09:05.665+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO CodeGenerator: Code generated in 16.135738 ms
[2022-12-30T09:09:05.678+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO CodeGenerator: Code generated in 4.345224 ms
[2022-12-30T09:09:05.699+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO CodeGenerator: Code generated in 11.792727 ms
[2022-12-30T09:09:05.707+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:09:05.785+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.2.15:33173 in memory (size: 9.9 KiB, free: 434.3 MiB)
[2022-12-30T09:09:05.877+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:05 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.2.15:33173 in memory (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:06.036+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2810 bytes result sent to driver
[2022-12-30T09:09:06.041+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 422 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:06.041+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2022-12-30T09:09:06.045+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0,443 s
[2022-12-30T09:09:06.045+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:09:06.045+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: running: Set()
[2022-12-30T09:09:06.045+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:09:06.046+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: failed: Set()
[2022-12-30T09:09:06.080+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T09:09:06.108+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:09:06.142+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO CodeGenerator: Code generated in 16.3654 ms
[2022-12-30T09:09:06.177+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2022-12-30T09:09:06.177+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:06.177+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:06.178+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2022-12-30T09:09:06.178+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:06.179+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:06.203+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 62.1 KiB, free 434.0 MiB)
[2022-12-30T09:09:06.205+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 434.0 MiB)
[2022-12-30T09:09:06.206+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.2.15:33173 (size: 23.7 KiB, free: 434.3 MiB)
[2022-12-30T09:09:06.208+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:06.209+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:06.209+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2022-12-30T09:09:06.219+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:06.219+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
[2022-12-30T09:09:06.321+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:09:06.324+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 29 ms
[2022-12-30T09:09:06.443+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 4309 bytes result sent to driver
[2022-12-30T09:09:06.454+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 235 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:06.454+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2022-12-30T09:09:06.457+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0,265 s
[2022-12-30T09:09:06.457+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:09:06.457+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: running: Set()
[2022-12-30T09:09:06.457+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:09:06.457+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: failed: Set()
[2022-12-30T09:09:06.489+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO CodeGenerator: Code generated in 13.995624 ms
[2022-12-30T09:09:06.521+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:06.524+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:06.524+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:06.524+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2022-12-30T09:09:06.524+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:06.527+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:06.527+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.1 KiB, free 434.0 MiB)
[2022-12-30T09:09:06.552+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.2.15:33173 in memory (size: 23.7 KiB, free: 434.3 MiB)
[2022-12-30T09:09:06.553+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.1 MiB)
[2022-12-30T09:09:06.555+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.2.15:33173 (size: 5.5 KiB, free: 434.3 MiB)
[2022-12-30T09:09:06.556+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:06.556+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:06.557+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2022-12-30T09:09:06.559+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:06.560+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO Executor: Running task 0.0 in stage 8.0 (TID 5)
[2022-12-30T09:09:06.571+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:09:06.572+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2022-12-30T09:09:06.590+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO Executor: Finished task 0.0 in stage 8.0 (TID 5). 2699 bytes result sent to driver
[2022-12-30T09:09:06.591+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 33 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:06.595+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2022-12-30T09:09:06.595+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0,067 s
[2022-12-30T09:09:06.595+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:09:06.595+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2022-12-30T09:09:06.595+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0,072225 s
[2022-12-30T09:09:06.597+0100] {spark_submit.py:495} INFO - ************Distinct count**************** :577
[2022-12-30T09:09:06.622+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.2.15:33173 in memory (size: 22.0 KiB, free: 434.4 MiB)
[2022-12-30T09:09:06.739+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:09:06.740+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:09:06.740+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T09:09:06.802+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:09:06.822+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 199.4 KiB, free 434.0 MiB)
[2022-12-30T09:09:06.831+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.9 MiB)
[2022-12-30T09:09:06.832+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.2.15:33173 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:06.835+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO SparkContext: Created broadcast 10 from showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:06.839+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:09:06.848+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Registering RDD 27 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2022-12-30T09:09:06.849+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Got map stage job 6 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:06.849+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:06.849+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:09:06.849+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:06.853+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:06.858+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 57.4 KiB, free 433.9 MiB)
[2022-12-30T09:09:06.886+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 433.9 MiB)
[2022-12-30T09:09:06.887+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.2.15:33173 (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:06.889+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:06.890+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:06.891+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2022-12-30T09:09:06.893+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:06.893+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO Executor: Running task 0.0 in stage 9.0 (TID 6)
[2022-12-30T09:09:06.914+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.2.15:33173 in memory (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:06.954+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:09:06.992+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:06 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.2.15:33173 in memory (size: 5.5 KiB, free: 434.3 MiB)
[2022-12-30T09:09:07.094+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO Executor: Finished task 0.0 in stage 9.0 (TID 6). 2724 bytes result sent to driver
[2022-12-30T09:09:07.098+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 203 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:07.098+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2022-12-30T09:09:07.098+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0) finished in 0,245 s
[2022-12-30T09:09:07.098+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:09:07.098+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: running: Set()
[2022-12-30T09:09:07.098+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:09:07.098+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: failed: Set()
[2022-12-30T09:09:07.103+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T09:09:07.115+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:09:07.169+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO CodeGenerator: Code generated in 44.072976 ms
[2022-12-30T09:09:07.197+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:07.199+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:07.199+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Final stage: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:07.199+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2022-12-30T09:09:07.199+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:07.204+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[30] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:07.221+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 73.4 KiB, free 434.0 MiB)
[2022-12-30T09:09:07.241+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 434.0 MiB)
[2022-12-30T09:09:07.242+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.2.15:33173 (size: 25.7 KiB, free: 434.3 MiB)
[2022-12-30T09:09:07.246+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:07.248+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[30] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:07.248+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2022-12-30T09:09:07.248+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 7) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:07.249+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO Executor: Running task 0.0 in stage 11.0 (TID 7)
[2022-12-30T09:09:07.253+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.2.15:33173 in memory (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:07.267+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:09:07.267+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2022-12-30T09:09:07.308+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO Executor: Finished task 0.0 in stage 11.0 (TID 7). 7622 bytes result sent to driver
[2022-12-30T09:09:07.309+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 7) in 61 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:07.309+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2022-12-30T09:09:07.312+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0) finished in 0,099 s
[2022-12-30T09:09:07.312+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:09:07.314+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2022-12-30T09:09:07.314+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 0,114640 s
[2022-12-30T09:09:07.330+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:09:07.330+0100] {spark_submit.py:495} INFO - |Code du département|Libellé du département         |Code de la circonscription|Libellé de la circonscription|Etat saisie|Inscrits|Abstentions|% Abs/Ins|Votants|% Vot/Ins|Blancs|% Blancs/Ins|% Blancs/Vot|Nuls|% Nuls/Ins|% Nuls/Vot|Exprimés|% Exp/Ins|% Exp/Vot|N°Panneau|Sexe|Nom    |Prénom  |Voix|% Voix/Ins|% Voix/Exp|
[2022-12-30T09:09:07.330+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:09:07.330+0100] {spark_submit.py:495} INFO - |06                 |Alpes-Maritimes                |5                         |5ème circonscription         |Complet    |90651   |24266      |26.77    |66385  |73.23    |847   |0.93        |1.28        |843 |0.93      |1.27      |64695   |71.37    |97.45    |1        |F   |ARTHAUD|Nathalie|196 |0.22      |0.3       |
[2022-12-30T09:09:07.330+0100] {spark_submit.py:495} INFO - |ZZ                 |Français établis hors de France|10                        |10ème circonscription        |Complet    |103910  |63575      |61.18    |40335  |38.82    |365   |0.35        |0.9         |191 |0.18      |0.47      |39779   |38.28    |98.62    |1        |F   |ARTHAUD|Nathalie|90  |0.09      |0.23      |
[2022-12-30T09:09:07.330+0100] {spark_submit.py:495} INFO - |24                 |Dordogne                       |2                         |2ème circonscription         |Complet    |84067   |18394      |21.88    |65673  |78.12    |832   |0.99        |1.27        |580 |0.69      |0.88      |64261   |76.44    |97.85    |1        |F   |ARTHAUD|Nathalie|314 |0.37      |0.49      |
[2022-12-30T09:09:07.330+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |2                         |2ème circonscription         |Complet    |85933   |16008      |18.63    |69925  |81.37    |877   |1.02        |1.25        |287 |0.33      |0.41      |68761   |80.02    |98.34    |1        |F   |ARTHAUD|Nathalie|220 |0.26      |0.32      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |ZB                 |Martinique                     |1                         |1ère circonscription         |Complet    |80037   |44808      |55.98    |35229  |44.02    |1154  |1.44        |3.28        |823 |1.03      |2.34      |33252   |41.55    |94.39    |1        |F   |ARTHAUD|Nathalie|432 |0.54      |1.3       |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |ZC                 |Guyane                         |1                         |1ère circonscription         |Complet    |56628   |32823      |57.96    |23805  |42.04    |556   |0.98        |2.34        |377 |0.67      |1.58      |22872   |40.39    |96.08    |1        |F   |ARTHAUD|Nathalie|176 |0.31      |0.77      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |01                 |Ain                            |1                         |1ère circonscription         |Complet    |85723   |18592      |21.69    |67131  |78.31    |1154  |1.35        |1.72        |393 |0.46      |0.59      |65584   |76.51    |97.7     |1        |F   |ARTHAUD|Nathalie|317 |0.37      |0.48      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |61                 |Orne                           |2                         |2ème circonscription         |Complet    |66030   |16122      |24.42    |49908  |75.58    |817   |1.24        |1.64        |278 |0.42      |0.56      |48813   |73.93    |97.81    |1        |F   |ARTHAUD|Nathalie|330 |0.5       |0.68      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |11                        |11ème circonscription        |Complet    |68878   |16249      |23.59    |52629  |76.41    |692   |1.0         |1.31        |318 |0.46      |0.6       |51619   |74.94    |98.08    |1        |F   |ARTHAUD|Nathalie|227 |0.33      |0.44      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |12                        |12ème circonscription        |Complet    |70828   |15015      |21.2     |55813  |78.8     |815   |1.15        |1.46        |233 |0.33      |0.42      |54765   |77.32    |98.12    |1        |F   |ARTHAUD|Nathalie|222 |0.31      |0.41      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |50                 |Manche                         |2                         |2ème circonscription         |Complet    |96973   |22676      |23.38    |74297  |76.62    |1262  |1.3         |1.7         |607 |0.63      |0.82      |72428   |74.69    |97.48    |1        |F   |ARTHAUD|Nathalie|524 |0.54      |0.72      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |9                         |9ème circonscription         |Complet    |92669   |21481      |23.18    |71188  |76.82    |1021  |1.1         |1.43        |361 |0.39      |0.51      |69806   |75.33    |98.06    |1        |F   |ARTHAUD|Nathalie|366 |0.39      |0.52      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |92                 |Hauts-de-Seine                 |2                         |2ème circonscription         |Complet    |69068   |13416      |19.42    |55652  |80.58    |795   |1.15        |1.43        |216 |0.31      |0.39      |54641   |79.11    |98.18    |1        |F   |ARTHAUD|Nathalie|169 |0.24      |0.31      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |60                 |Oise                           |2                         |2ème circonscription         |Complet    |88749   |21439      |24.16    |67310  |75.84    |1016  |1.14        |1.51        |1150|1.3       |1.71      |65144   |73.4     |96.78    |1        |F   |ARTHAUD|Nathalie|475 |0.54      |0.73      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |13                 |Bouches-du-Rhône               |10                        |10ème circonscription        |Complet    |108586  |24129      |22.22    |84457  |77.78    |1235  |1.14        |1.46        |448 |0.41      |0.53      |82774   |76.23    |98.01    |1        |F   |ARTHAUD|Nathalie|269 |0.25      |0.32      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |1                         |1ère circonscription         |Complet    |97799   |19432      |19.87    |78367  |80.13    |898   |0.92        |1.15        |416 |0.43      |0.53      |77053   |78.79    |98.32    |1        |F   |ARTHAUD|Nathalie|183 |0.19      |0.24      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |91                 |Essonne                        |9                         |9ème circonscription         |Complet    |78393   |18934      |24.15    |59459  |75.85    |870   |1.11        |1.46        |335 |0.43      |0.56      |58254   |74.31    |97.97    |1        |F   |ARTHAUD|Nathalie|265 |0.34      |0.45      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |14                 |Calvados                       |6                         |6ème circonscription         |Complet    |95726   |21470      |22.43    |74256  |77.57    |1179  |1.23        |1.59        |589 |0.62      |0.79      |72488   |75.72    |97.62    |1        |F   |ARTHAUD|Nathalie|581 |0.61      |0.8       |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |22                 |Côtes-d'Armor                  |3                         |3ème circonscription         |Complet    |88709   |17554      |19.79    |71155  |80.21    |1189  |1.34        |1.67        |645 |0.73      |0.91      |69321   |78.14    |97.42    |1        |F   |ARTHAUD|Nathalie|521 |0.59      |0.75      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |10                        |10ème circonscription        |Complet    |69820   |15846      |22.7     |53974  |77.3     |641   |0.92        |1.19        |233 |0.33      |0.43      |53100   |76.05    |98.38    |1        |F   |ARTHAUD|Nathalie|206 |0.3       |0.39      |
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:09:07.331+0100] {spark_submit.py:495} INFO - only showing top 20 rows
[2022-12-30T09:09:07.332+0100] {spark_submit.py:495} INFO - 
[2022-12-30T09:09:07.469+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:09:07.469+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:09:07.469+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T09:09:07.486+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:09:07.530+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 199.4 KiB, free 433.9 MiB)
[2022-12-30T09:09:07.555+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.8 MiB)
[2022-12-30T09:09:07.556+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.2.15:33173 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:07.559+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO SparkContext: Created broadcast 13 from count at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:07.560+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:09:07.581+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2022-12-30T09:09:07.581+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Got map stage job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:07.581+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:07.582+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:09:07.582+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:07.592+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:07.614+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 57.4 KiB, free 433.8 MiB)
[2022-12-30T09:09:07.660+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 433.8 MiB)
[2022-12-30T09:09:07.662+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.2.15:33173 (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:07.667+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:07.670+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:07.671+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2022-12-30T09:09:07.671+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 8) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:07.671+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO Executor: Running task 0.0 in stage 12.0 (TID 8)
[2022-12-30T09:09:07.746+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.2.15:33173 in memory (size: 25.7 KiB, free: 434.3 MiB)
[2022-12-30T09:09:07.784+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:09:07.825+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:07 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.2.15:33173 in memory (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:08.029+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO Executor: Finished task 0.0 in stage 12.0 (TID 8). 2724 bytes result sent to driver
[2022-12-30T09:09:08.036+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 8) in 367 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:08.036+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2022-12-30T09:09:08.039+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0,447 s
[2022-12-30T09:09:08.039+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:09:08.039+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: running: Set()
[2022-12-30T09:09:08.039+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:09:08.039+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: failed: Set()
[2022-12-30T09:09:08.055+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T09:09:08.072+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:09:08.100+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Registering RDD 37 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2022-12-30T09:09:08.101+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Got map stage job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:08.101+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:08.101+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2022-12-30T09:09:08.101+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:08.103+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:08.120+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 62.1 KiB, free 434.0 MiB)
[2022-12-30T09:09:08.153+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 434.0 MiB)
[2022-12-30T09:09:08.154+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.2.15:33173 (size: 23.7 KiB, free: 434.3 MiB)
[2022-12-30T09:09:08.155+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:08.156+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:08.158+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2022-12-30T09:09:08.166+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 9) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:08.166+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO Executor: Running task 0.0 in stage 14.0 (TID 9)
[2022-12-30T09:09:08.192+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.2.15:33173 in memory (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:08.197+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:09:08.197+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2022-12-30T09:09:08.253+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO Executor: Finished task 0.0 in stage 14.0 (TID 9). 4309 bytes result sent to driver
[2022-12-30T09:09:08.255+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 9) in 91 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:08.255+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2022-12-30T09:09:08.256+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0,140 s
[2022-12-30T09:09:08.258+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:09:08.258+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: running: Set()
[2022-12-30T09:09:08.258+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:09:08.258+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: failed: Set()
[2022-12-30T09:09:08.384+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:08.386+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:08.386+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Final stage: ResultStage 17 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:08.387+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
[2022-12-30T09:09:08.387+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:08.388+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:08.401+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 11.1 KiB, free 434.1 MiB)
[2022-12-30T09:09:08.406+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.1 MiB)
[2022-12-30T09:09:08.407+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.2.15:33173 (size: 5.5 KiB, free: 434.3 MiB)
[2022-12-30T09:09:08.407+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:08.408+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:08.410+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2022-12-30T09:09:08.414+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 10) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:08.417+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO Executor: Running task 0.0 in stage 17.0 (TID 10)
[2022-12-30T09:09:08.427+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:09:08.428+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2022-12-30T09:09:08.439+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO Executor: Finished task 0.0 in stage 17.0 (TID 10). 2656 bytes result sent to driver
[2022-12-30T09:09:08.440+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 10) in 31 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:08.440+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2022-12-30T09:09:08.447+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: ResultStage 17 (count at NativeMethodAccessorImpl.java:0) finished in 0,052 s
[2022-12-30T09:09:08.448+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:09:08.448+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
[2022-12-30T09:09:08.451+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0,063872 s
[2022-12-30T09:09:08.455+0100] {spark_submit.py:495} INFO - ****************Distinct count drop******************* :577
[2022-12-30T09:09:08.570+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:09:08.576+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:09:08.578+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T09:09:08.656+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:09:08.672+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 199.4 KiB, free 433.9 MiB)
[2022-12-30T09:09:08.704+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.8 MiB)
[2022-12-30T09:09:08.705+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.2.15:33173 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:08.706+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO SparkContext: Created broadcast 17 from showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:08.709+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:09:08.721+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Registering RDD 44 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2022-12-30T09:09:08.722+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Got map stage job 11 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:08.722+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Final stage: ShuffleMapStage 18 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:08.722+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:09:08.722+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:08.725+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[44] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:08.728+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.2.15:33173 in memory (size: 5.5 KiB, free: 434.3 MiB)
[2022-12-30T09:09:08.753+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 57.4 KiB, free 433.8 MiB)
[2022-12-30T09:09:08.753+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 433.8 MiB)
[2022-12-30T09:09:08.753+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.2.15:33173 (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:08.753+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:08.754+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[44] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:08.754+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2022-12-30T09:09:08.754+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 11) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:08.755+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO Executor: Running task 0.0 in stage 18.0 (TID 11)
[2022-12-30T09:09:08.784+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.2.15:33173 in memory (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:08.813+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:09:08.889+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:08 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.2.15:33173 in memory (size: 23.7 KiB, free: 434.3 MiB)
[2022-12-30T09:09:09.012+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO Executor: Finished task 0.0 in stage 18.0 (TID 11). 2724 bytes result sent to driver
[2022-12-30T09:09:09.013+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 11) in 260 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:09.013+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2022-12-30T09:09:09.016+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: ShuffleMapStage 18 (showString at NativeMethodAccessorImpl.java:0) finished in 0,284 s
[2022-12-30T09:09:09.016+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:09:09.016+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: running: Set()
[2022-12-30T09:09:09.016+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:09:09.016+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: failed: Set()
[2022-12-30T09:09:09.023+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T09:09:09.032+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:09:09.063+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:09:09.063+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: Got job 12 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:09:09.063+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: Final stage: ResultStage 20 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:09:09.063+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2022-12-30T09:09:09.063+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:09:09.071+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:09:09.085+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 73.4 KiB, free 434.0 MiB)
[2022-12-30T09:09:09.119+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 434.0 MiB)
[2022-12-30T09:09:09.123+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.2.15:33173 (size: 25.7 KiB, free: 434.3 MiB)
[2022-12-30T09:09:09.128+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:09:09.132+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:09:09.132+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2022-12-30T09:09:09.132+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 12) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T09:09:09.132+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO Executor: Running task 0.0 in stage 20.0 (TID 12)
[2022-12-30T09:09:09.142+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.2.15:33173 in memory (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:09:09.171+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:09:09.183+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 13 ms
[2022-12-30T09:09:09.230+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO Executor: Finished task 0.0 in stage 20.0 (TID 12). 7622 bytes result sent to driver
[2022-12-30T09:09:09.244+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 12) in 117 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:09:09.244+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2022-12-30T09:09:09.248+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: ResultStage 20 (showString at NativeMethodAccessorImpl.java:0) finished in 0,171 s
[2022-12-30T09:09:09.248+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:09:09.248+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2022-12-30T09:09:09.248+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO DAGScheduler: Job 12 finished: showString at NativeMethodAccessorImpl.java:0, took 0,184491 s
[2022-12-30T09:09:09.279+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:09:09.281+0100] {spark_submit.py:495} INFO - |Code du département|Libellé du département         |Code de la circonscription|Libellé de la circonscription|Etat saisie|Inscrits|Abstentions|% Abs/Ins|Votants|% Vot/Ins|Blancs|% Blancs/Ins|% Blancs/Vot|Nuls|% Nuls/Ins|% Nuls/Vot|Exprimés|% Exp/Ins|% Exp/Vot|N°Panneau|Sexe|Nom    |Prénom  |Voix|% Voix/Ins|% Voix/Exp|
[2022-12-30T09:09:09.281+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:09:09.281+0100] {spark_submit.py:495} INFO - |06                 |Alpes-Maritimes                |5                         |5ème circonscription         |Complet    |90651   |24266      |26.77    |66385  |73.23    |847   |0.93        |1.28        |843 |0.93      |1.27      |64695   |71.37    |97.45    |1        |F   |ARTHAUD|Nathalie|196 |0.22      |0.3       |
[2022-12-30T09:09:09.281+0100] {spark_submit.py:495} INFO - |ZZ                 |Français établis hors de France|10                        |10ème circonscription        |Complet    |103910  |63575      |61.18    |40335  |38.82    |365   |0.35        |0.9         |191 |0.18      |0.47      |39779   |38.28    |98.62    |1        |F   |ARTHAUD|Nathalie|90  |0.09      |0.23      |
[2022-12-30T09:09:09.281+0100] {spark_submit.py:495} INFO - |24                 |Dordogne                       |2                         |2ème circonscription         |Complet    |84067   |18394      |21.88    |65673  |78.12    |832   |0.99        |1.27        |580 |0.69      |0.88      |64261   |76.44    |97.85    |1        |F   |ARTHAUD|Nathalie|314 |0.37      |0.49      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |2                         |2ème circonscription         |Complet    |85933   |16008      |18.63    |69925  |81.37    |877   |1.02        |1.25        |287 |0.33      |0.41      |68761   |80.02    |98.34    |1        |F   |ARTHAUD|Nathalie|220 |0.26      |0.32      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |ZB                 |Martinique                     |1                         |1ère circonscription         |Complet    |80037   |44808      |55.98    |35229  |44.02    |1154  |1.44        |3.28        |823 |1.03      |2.34      |33252   |41.55    |94.39    |1        |F   |ARTHAUD|Nathalie|432 |0.54      |1.3       |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |ZC                 |Guyane                         |1                         |1ère circonscription         |Complet    |56628   |32823      |57.96    |23805  |42.04    |556   |0.98        |2.34        |377 |0.67      |1.58      |22872   |40.39    |96.08    |1        |F   |ARTHAUD|Nathalie|176 |0.31      |0.77      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |01                 |Ain                            |1                         |1ère circonscription         |Complet    |85723   |18592      |21.69    |67131  |78.31    |1154  |1.35        |1.72        |393 |0.46      |0.59      |65584   |76.51    |97.7     |1        |F   |ARTHAUD|Nathalie|317 |0.37      |0.48      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |61                 |Orne                           |2                         |2ème circonscription         |Complet    |66030   |16122      |24.42    |49908  |75.58    |817   |1.24        |1.64        |278 |0.42      |0.56      |48813   |73.93    |97.81    |1        |F   |ARTHAUD|Nathalie|330 |0.5       |0.68      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |11                        |11ème circonscription        |Complet    |68878   |16249      |23.59    |52629  |76.41    |692   |1.0         |1.31        |318 |0.46      |0.6       |51619   |74.94    |98.08    |1        |F   |ARTHAUD|Nathalie|227 |0.33      |0.44      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |12                        |12ème circonscription        |Complet    |70828   |15015      |21.2     |55813  |78.8     |815   |1.15        |1.46        |233 |0.33      |0.42      |54765   |77.32    |98.12    |1        |F   |ARTHAUD|Nathalie|222 |0.31      |0.41      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |50                 |Manche                         |2                         |2ème circonscription         |Complet    |96973   |22676      |23.38    |74297  |76.62    |1262  |1.3         |1.7         |607 |0.63      |0.82      |72428   |74.69    |97.48    |1        |F   |ARTHAUD|Nathalie|524 |0.54      |0.72      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |9                         |9ème circonscription         |Complet    |92669   |21481      |23.18    |71188  |76.82    |1021  |1.1         |1.43        |361 |0.39      |0.51      |69806   |75.33    |98.06    |1        |F   |ARTHAUD|Nathalie|366 |0.39      |0.52      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |92                 |Hauts-de-Seine                 |2                         |2ème circonscription         |Complet    |69068   |13416      |19.42    |55652  |80.58    |795   |1.15        |1.43        |216 |0.31      |0.39      |54641   |79.11    |98.18    |1        |F   |ARTHAUD|Nathalie|169 |0.24      |0.31      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |60                 |Oise                           |2                         |2ème circonscription         |Complet    |88749   |21439      |24.16    |67310  |75.84    |1016  |1.14        |1.51        |1150|1.3       |1.71      |65144   |73.4     |96.78    |1        |F   |ARTHAUD|Nathalie|475 |0.54      |0.73      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |13                 |Bouches-du-Rhône               |10                        |10ème circonscription        |Complet    |108586  |24129      |22.22    |84457  |77.78    |1235  |1.14        |1.46        |448 |0.41      |0.53      |82774   |76.23    |98.01    |1        |F   |ARTHAUD|Nathalie|269 |0.25      |0.32      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |1                         |1ère circonscription         |Complet    |97799   |19432      |19.87    |78367  |80.13    |898   |0.92        |1.15        |416 |0.43      |0.53      |77053   |78.79    |98.32    |1        |F   |ARTHAUD|Nathalie|183 |0.19      |0.24      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |91                 |Essonne                        |9                         |9ème circonscription         |Complet    |78393   |18934      |24.15    |59459  |75.85    |870   |1.11        |1.46        |335 |0.43      |0.56      |58254   |74.31    |97.97    |1        |F   |ARTHAUD|Nathalie|265 |0.34      |0.45      |
[2022-12-30T09:09:09.282+0100] {spark_submit.py:495} INFO - |14                 |Calvados                       |6                         |6ème circonscription         |Complet    |95726   |21470      |22.43    |74256  |77.57    |1179  |1.23        |1.59        |589 |0.62      |0.79      |72488   |75.72    |97.62    |1        |F   |ARTHAUD|Nathalie|581 |0.61      |0.8       |
[2022-12-30T09:09:09.283+0100] {spark_submit.py:495} INFO - |22                 |Côtes-d'Armor                  |3                         |3ème circonscription         |Complet    |88709   |17554      |19.79    |71155  |80.21    |1189  |1.34        |1.67        |645 |0.73      |0.91      |69321   |78.14    |97.42    |1        |F   |ARTHAUD|Nathalie|521 |0.59      |0.75      |
[2022-12-30T09:09:09.283+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |10                        |10ème circonscription        |Complet    |69820   |15846      |22.7     |53974  |77.3     |641   |0.92        |1.19        |233 |0.33      |0.43      |53100   |76.05    |98.38    |1        |F   |ARTHAUD|Nathalie|206 |0.3       |0.39      |
[2022-12-30T09:09:09.283+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:09:09.283+0100] {spark_submit.py:495} INFO - only showing top 20 rows
[2022-12-30T09:09:09.283+0100] {spark_submit.py:495} INFO - 
[2022-12-30T09:09:09.471+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO SparkContext: Invoking stop() from shutdown hook
[2022-12-30T09:09:09.492+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO SparkUI: Stopped Spark web UI at http://10.0.2.15:4040
[2022-12-30T09:09:09.511+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2022-12-30T09:09:09.544+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO MemoryStore: MemoryStore cleared
[2022-12-30T09:09:09.556+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO BlockManager: BlockManager stopped
[2022-12-30T09:09:09.570+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO BlockManagerMaster: BlockManagerMaster stopped
[2022-12-30T09:09:09.579+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2022-12-30T09:09:09.606+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO SparkContext: Successfully stopped SparkContext
[2022-12-30T09:09:09.607+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO ShutdownHookManager: Shutdown hook called
[2022-12-30T09:09:09.607+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-1f61036d-da14-403a-b6ab-b93ca2afbb2d
[2022-12-30T09:09:09.618+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-1f61036d-da14-403a-b6ab-b93ca2afbb2d/pyspark-bb2519b1-e0e9-417c-82b7-62c8df379166
[2022-12-30T09:09:09.620+0100] {spark_submit.py:495} INFO - 22/12/30 09:09:09 INFO ShutdownHookManager: Deleting directory /tmp/spark-dc44fb9b-8193-48bc-8ef0-28532eff6415
[2022-12-30T09:09:09.745+0100] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=spark_airflow_project, task_id=spark_job_process, execution_date=20221230T080823, start_date=20221230T080853, end_date=20221230T080909
[2022-12-30T09:09:09.793+0100] {local_task_job.py:159} INFO - Task exited with return code 0
[2022-12-30T09:09:09.820+0100] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
