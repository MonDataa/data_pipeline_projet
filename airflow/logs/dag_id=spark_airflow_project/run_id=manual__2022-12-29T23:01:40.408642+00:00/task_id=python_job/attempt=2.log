[2022-12-30T00:06:57.007+0100] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: spark_airflow_project.python_job manual__2022-12-29T23:01:40.408642+00:00 [queued]>
[2022-12-30T00:06:57.015+0100] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: spark_airflow_project.python_job manual__2022-12-29T23:01:40.408642+00:00 [queued]>
[2022-12-30T00:06:57.015+0100] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2022-12-30T00:06:57.015+0100] {taskinstance.py:1284} INFO - Starting attempt 2 of 4
[2022-12-30T00:06:57.015+0100] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2022-12-30T00:06:57.025+0100] {taskinstance.py:1304} INFO - Executing <Task(SparkSubmitOperator): python_job> on 2022-12-29 23:01:40.408642+00:00
[2022-12-30T00:06:57.028+0100] {standard_task_runner.py:55} INFO - Started process 14461 to run task
[2022-12-30T00:06:57.033+0100] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'spark_airflow_project', 'python_job', 'manual__2022-12-29T23:01:40.408642+00:00', '--job-id', '62', '--raw', '--subdir', 'DAGS_FOLDER/spark_airflow.py', '--cfg-path', '/tmp/tmp0x3aoyf1']
[2022-12-30T00:06:57.034+0100] {standard_task_runner.py:83} INFO - Job 62: Subtask python_job
[2022-12-30T00:06:57.074+0100] {task_command.py:389} INFO - Running <TaskInstance: spark_airflow_project.python_job manual__2022-12-29T23:01:40.408642+00:00 [running]> on host momo-VirtualBox
[2022-12-30T00:06:57.131+0100] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Ranga
AIRFLOW_CTX_DAG_ID=spark_airflow_project
AIRFLOW_CTX_TASK_ID=python_job
AIRFLOW_CTX_EXECUTION_DATE=2022-12-29T23:01:40.408642+00:00
AIRFLOW_CTX_TRY_NUMBER=2
AIRFLOW_CTX_DAG_RUN_ID=manual__2022-12-29T23:01:40.408642+00:00
[2022-12-30T00:06:57.138+0100] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2022-12-30T00:06:57.139+0100] {spark_submit.py:344} INFO - Spark-Submit cmd: spark-submit --master spark://momo-VirtualBox:7077 --name arrow-spark --queue root.default /home/momo/Bureau/spark_d2.py
[2022-12-30T00:06:59.686+0100] {spark_submit.py:495} INFO - 22/12/30 00:06:59 WARN Utils: Your hostname, momo-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
[2022-12-30T00:06:59.688+0100] {spark_submit.py:495} INFO - 22/12/30 00:06:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2022-12-30T00:07:00.774+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:00 INFO SparkContext: Running Spark version 3.3.1
[2022-12-30T00:07:00.911+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2022-12-30T00:07:01.110+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO ResourceUtils: ==============================================================
[2022-12-30T00:07:01.112+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO ResourceUtils: No custom resources configured for spark.driver.
[2022-12-30T00:07:01.113+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO ResourceUtils: ==============================================================
[2022-12-30T00:07:01.113+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO SparkContext: Submitted application: conf pro spark
[2022-12-30T00:07:01.146+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2022-12-30T00:07:01.174+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO ResourceProfile: Limiting resource is cpu
[2022-12-30T00:07:01.175+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2022-12-30T00:07:01.275+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO SecurityManager: Changing view acls to: momo
[2022-12-30T00:07:01.280+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO SecurityManager: Changing modify acls to: momo
[2022-12-30T00:07:01.281+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO SecurityManager: Changing view acls groups to:
[2022-12-30T00:07:01.282+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO SecurityManager: Changing modify acls groups to:
[2022-12-30T00:07:01.282+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(momo); groups with view permissions: Set(); users  with modify permissions: Set(momo); groups with modify permissions: Set()
[2022-12-30T00:07:01.741+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO Utils: Successfully started service 'sparkDriver' on port 45263.
[2022-12-30T00:07:01.791+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO SparkEnv: Registering MapOutputTracker
[2022-12-30T00:07:01.847+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO SparkEnv: Registering BlockManagerMaster
[2022-12-30T00:07:01.900+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2022-12-30T00:07:01.901+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2022-12-30T00:07:01.905+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2022-12-30T00:07:01.941+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-57bbccb0-9f7a-484f-a81a-1ad0fd21ec4c
[2022-12-30T00:07:01.963+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:01 INFO MemoryStore: MemoryStore started with capacity 413.9 MiB
[2022-12-30T00:07:02.003+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:02 INFO SparkEnv: Registering OutputCommitCoordinator
[2022-12-30T00:07:02.377+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:02 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2022-12-30T00:07:02.551+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:02 INFO Executor: Starting executor ID driver on host 10.0.2.15
[2022-12-30T00:07:02.567+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:02 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2022-12-30T00:07:02.609+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:02 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 45963.
[2022-12-30T00:07:02.609+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:02 INFO NettyBlockTransferService: Server created on 10.0.2.15:45963
[2022-12-30T00:07:02.611+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:02 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2022-12-30T00:07:02.617+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:02 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.2.15, 45963, None)
[2022-12-30T00:07:02.623+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:02 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.15:45963 with 413.9 MiB RAM, BlockManagerId(driver, 10.0.2.15, 45963, None)
[2022-12-30T00:07:02.632+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:02 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.2.15, 45963, None)
[2022-12-30T00:07:02.633+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:02 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.2.15, 45963, None)
[2022-12-30T00:07:03.348+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:03 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2022-12-30T00:07:03.363+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:03 INFO SharedState: Warehouse path is 'file:/home/momo/Bureau/spark-warehouse'.
[2022-12-30T00:07:04.884+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:04 INFO InMemoryFileIndex: It took 174 ms to list leaf files for 1 paths.
[2022-12-30T00:07:05.087+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:05 INFO InMemoryFileIndex: It took 7 ms to list leaf files for 1 paths.
[2022-12-30T00:07:10.119+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:10 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T00:07:10.128+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:10 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
[2022-12-30T00:07:10.145+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:10 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
[2022-12-30T00:07:11.426+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO CodeGenerator: Code generated in 264.680291 ms
[2022-12-30T00:07:11.564+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.6 KiB, free 413.7 MiB)
[2022-12-30T00:07:11.691+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 413.7 MiB)
[2022-12-30T00:07:11.694+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.15:45963 (size: 34.0 KiB, free: 413.9 MiB)
[2022-12-30T00:07:11.701+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:11.711+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T00:07:11.902+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:11.935+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:11.935+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:11.936+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T00:07:11.937+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:11.949+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:11 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:12.086+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.8 KiB, free 413.7 MiB)
[2022-12-30T00:07:12.095+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 413.7 MiB)
[2022-12-30T00:07:12.099+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.15:45963 (size: 5.9 KiB, free: 413.9 MiB)
[2022-12-30T00:07:12.100+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:12.126+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:12.133+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2022-12-30T00:07:12.221+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:12.257+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2022-12-30T00:07:12.499+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T00:07:12.558+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO CodeGenerator: Code generated in 41.905516 ms
[2022-12-30T00:07:12.680+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1792 bytes result sent to driver
[2022-12-30T00:07:12.701+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 503 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:12.707+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2022-12-30T00:07:12.720+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0,735 s
[2022-12-30T00:07:12.730+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T00:07:12.730+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2022-12-30T00:07:12.739+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0,826203 s
[2022-12-30T00:07:12.778+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO CodeGenerator: Code generated in 23.491287 ms
[2022-12-30T00:07:12.877+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T00:07:12.877+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T00:07:12.878+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
[2022-12-30T00:07:12.892+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 199.6 KiB, free 413.5 MiB)
[2022-12-30T00:07:12.913+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 413.5 MiB)
[2022-12-30T00:07:12.914+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.2.15:45963 (size: 34.0 KiB, free: 413.9 MiB)
[2022-12-30T00:07:12.923+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:12.925+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T00:07:13.112+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:13.114+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:13.114+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:13.114+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T00:07:13.114+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:13.117+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:13.213+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 25.0 KiB, free 413.4 MiB)
[2022-12-30T00:07:13.215+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 413.4 MiB)
[2022-12-30T00:07:13.217+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.2.15:45963 (size: 11.8 KiB, free: 413.8 MiB)
[2022-12-30T00:07:13.218+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:13.223+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:13.224+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2022-12-30T00:07:13.226+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:13.226+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2022-12-30T00:07:13.299+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T00:07:13.447+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1780 bytes result sent to driver
[2022-12-30T00:07:13.464+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 239 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:13.474+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0,347 s
[2022-12-30T00:07:13.477+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T00:07:13.477+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2022-12-30T00:07:13.479+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2022-12-30T00:07:13.484+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0,371303 s
[2022-12-30T00:07:13.559+0100] {spark_submit.py:495} INFO - root
[2022-12-30T00:07:13.560+0100] {spark_submit.py:495} INFO - |-- Code du département: string (nullable = true)
[2022-12-30T00:07:13.560+0100] {spark_submit.py:495} INFO - |-- Libellé du département: string (nullable = true)
[2022-12-30T00:07:13.560+0100] {spark_submit.py:495} INFO - |-- Code de la circonscription: integer (nullable = true)
[2022-12-30T00:07:13.560+0100] {spark_submit.py:495} INFO - |-- Libellé de la circonscription: string (nullable = true)
[2022-12-30T00:07:13.560+0100] {spark_submit.py:495} INFO - |-- Etat saisie: string (nullable = true)
[2022-12-30T00:07:13.560+0100] {spark_submit.py:495} INFO - |-- Inscrits: integer (nullable = true)
[2022-12-30T00:07:13.560+0100] {spark_submit.py:495} INFO - |-- Abstentions: integer (nullable = true)
[2022-12-30T00:07:13.560+0100] {spark_submit.py:495} INFO - |-- % Abs/Ins: double (nullable = true)
[2022-12-30T00:07:13.560+0100] {spark_submit.py:495} INFO - |-- Votants: integer (nullable = true)
[2022-12-30T00:07:13.560+0100] {spark_submit.py:495} INFO - |-- % Vot/Ins: double (nullable = true)
[2022-12-30T00:07:13.561+0100] {spark_submit.py:495} INFO - |-- Blancs: integer (nullable = true)
[2022-12-30T00:07:13.561+0100] {spark_submit.py:495} INFO - |-- % Blancs/Ins: double (nullable = true)
[2022-12-30T00:07:13.561+0100] {spark_submit.py:495} INFO - |-- % Blancs/Vot: double (nullable = true)
[2022-12-30T00:07:13.561+0100] {spark_submit.py:495} INFO - |-- Nuls: integer (nullable = true)
[2022-12-30T00:07:13.561+0100] {spark_submit.py:495} INFO - |-- % Nuls/Ins: double (nullable = true)
[2022-12-30T00:07:13.561+0100] {spark_submit.py:495} INFO - |-- % Nuls/Vot: double (nullable = true)
[2022-12-30T00:07:13.561+0100] {spark_submit.py:495} INFO - |-- Exprimés: integer (nullable = true)
[2022-12-30T00:07:13.561+0100] {spark_submit.py:495} INFO - |-- % Exp/Ins: double (nullable = true)
[2022-12-30T00:07:13.561+0100] {spark_submit.py:495} INFO - |-- % Exp/Vot: double (nullable = true)
[2022-12-30T00:07:13.561+0100] {spark_submit.py:495} INFO - |-- N°Panneau: integer (nullable = true)
[2022-12-30T00:07:13.561+0100] {spark_submit.py:495} INFO - |-- Sexe: string (nullable = true)
[2022-12-30T00:07:13.562+0100] {spark_submit.py:495} INFO - |-- Nom: string (nullable = true)
[2022-12-30T00:07:13.562+0100] {spark_submit.py:495} INFO - |-- Prénom: string (nullable = true)
[2022-12-30T00:07:13.562+0100] {spark_submit.py:495} INFO - |-- Voix: integer (nullable = true)
[2022-12-30T00:07:13.562+0100] {spark_submit.py:495} INFO - |-- % Voix/Ins: double (nullable = true)
[2022-12-30T00:07:13.562+0100] {spark_submit.py:495} INFO - |-- % Voix/Exp: double (nullable = true)
[2022-12-30T00:07:13.562+0100] {spark_submit.py:495} INFO - 
[2022-12-30T00:07:13.749+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T00:07:13.749+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T00:07:13.751+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T00:07:13.780+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2022-12-30T00:07:13.869+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:13 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.2.15:45963 in memory (size: 11.8 KiB, free: 413.9 MiB)
[2022-12-30T00:07:14.052+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO CodeGenerator: Code generated in 116.398425 ms
[2022-12-30T00:07:14.066+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 199.4 KiB, free 413.3 MiB)
[2022-12-30T00:07:14.081+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 413.2 MiB)
[2022-12-30T00:07:14.082+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.2.15:45963 (size: 34.0 KiB, free: 413.8 MiB)
[2022-12-30T00:07:14.083+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO SparkContext: Created broadcast 4 from showString at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:14.086+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T00:07:14.124+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:14.125+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:14.126+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:14.126+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T00:07:14.126+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:14.128+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:14.133+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 27.1 KiB, free 413.2 MiB)
[2022-12-30T00:07:14.135+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 413.2 MiB)
[2022-12-30T00:07:14.145+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.2.15:45963 (size: 9.9 KiB, free: 413.8 MiB)
[2022-12-30T00:07:14.145+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:14.146+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:14.146+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2022-12-30T00:07:14.148+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:14.148+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
[2022-12-30T00:07:14.165+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T00:07:14.276+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO CodeGenerator: Code generated in 55.160429 ms
[2022-12-30T00:07:14.340+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 4556 bytes result sent to driver
[2022-12-30T00:07:14.347+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 200 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:14.350+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 0,220 s
[2022-12-30T00:07:14.350+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T00:07:14.351+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2022-12-30T00:07:14.353+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2022-12-30T00:07:14.353+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0,226847 s
[2022-12-30T00:07:14.442+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO CodeGenerator: Code generated in 67.225114 ms
[2022-12-30T00:07:14.481+0100] {spark_submit.py:495} INFO - +-------------------+----------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T00:07:14.481+0100] {spark_submit.py:495} INFO - |Code du département|Libellé du département|Code de la circonscription|Libellé de la circonscription|Etat saisie|Inscrits|Abstentions|% Abs/Ins|Votants|% Vot/Ins|Blancs|% Blancs/Ins|% Blancs/Vot|Nuls|% Nuls/Ins|% Nuls/Vot|Exprimés|% Exp/Ins|% Exp/Vot|N°Panneau|Sexe|    Nom|  Prénom|Voix|% Voix/Ins|% Voix/Exp|
[2022-12-30T00:07:14.481+0100] {spark_submit.py:495} INFO - +-------------------+----------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T00:07:14.481+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         1|         1ère circonscription|    Complet|   85723|      18592|    21.69|  67131|    78.31|  1154|        1.35|        1.72| 393|      0.46|      0.59|   65584|    76.51|     97.7|        1|   F|ARTHAUD|Nathalie| 317|      0.37|      0.48|
[2022-12-30T00:07:14.481+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         2|         2ème circonscription|    Complet|   99383|      19917|    20.04|  79466|    79.96|  1367|        1.38|        1.72| 352|      0.35|      0.44|   77747|    78.23|    97.84|        1|   F|ARTHAUD|Nathalie| 354|      0.36|      0.46|
[2022-12-30T00:07:14.481+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         3|         3ème circonscription|    Complet|   81500|      20440|    25.08|  61060|    74.92|   851|        1.04|        1.39| 290|      0.36|      0.47|   59919|    73.52|    98.13|        1|   F|ARTHAUD|Nathalie| 275|      0.34|      0.46|
[2022-12-30T00:07:14.481+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         4|         4ème circonscription|    Complet|   94359|      19826|    21.01|  74533|    78.99|  1299|        1.38|        1.74| 474|       0.5|      0.64|   72760|    77.11|    97.62|        1|   F|ARTHAUD|Nathalie| 376|       0.4|      0.52|
[2022-12-30T00:07:14.481+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         5|         5ème circonscription|    Complet|   77144|      18766|    24.33|  58378|    75.67|   970|        1.26|        1.66| 394|      0.51|      0.67|   57014|    73.91|    97.66|        1|   F|ARTHAUD|Nathalie| 336|      0.44|      0.59|
[2022-12-30T00:07:14.481+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         1|         1ère circonscription|    Complet|   72206|      18597|    25.76|  53609|    74.24|   740|        1.02|        1.38| 404|      0.56|      0.75|   52465|    72.66|    97.87|        1|   F|ARTHAUD|Nathalie| 410|      0.57|      0.78|
[2022-12-30T00:07:14.481+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         2|         2ème circonscription|    Complet|   73111|      20530|    28.08|  52581|    71.92|   772|        1.06|        1.47| 403|      0.55|      0.77|   51406|    70.31|    97.77|        1|   F|ARTHAUD|Nathalie| 372|      0.51|      0.72|
[2022-12-30T00:07:14.481+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         3|         3ème circonscription|    Complet|   66580|      17358|    26.07|  49222|    73.93|   699|        1.05|        1.42| 398|       0.6|      0.81|   48125|    72.28|    97.77|        1|   F|ARTHAUD|Nathalie| 358|      0.54|      0.74|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         4|         4ème circonscription|    Complet|   78699|      22961|    29.18|  55738|    70.82|   681|        0.87|        1.22|1143|      1.45|      2.05|   53914|    68.51|    96.73|        1|   F|ARTHAUD|Nathalie| 391|       0.5|      0.73|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         5|         5ème circonscription|    Complet|   82948|      21643|    26.09|  61305|    73.91|   875|        1.05|        1.43| 480|      0.58|      0.78|   59950|    72.27|    97.79|        1|   F|ARTHAUD|Nathalie| 507|      0.61|      0.85|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 03|                Allier|                         1|         1ère circonscription|    Complet|   89193|      20597|    23.09|  68596|    76.91|  1330|        1.49|        1.94| 599|      0.67|      0.87|   66667|    74.74|    97.19|        1|   F|ARTHAUD|Nathalie| 528|      0.59|      0.79|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 03|                Allier|                         2|         2ème circonscription|    Complet|   80780|      19459|    24.09|  61321|    75.91|  1207|        1.49|        1.97| 649|       0.8|      1.06|   59465|    73.61|    96.97|        1|   F|ARTHAUD|Nathalie| 446|      0.55|      0.75|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 03|                Allier|                         3|         3ème circonscription|    Complet|   80018|      18441|    23.05|  61577|    76.95|  1212|        1.51|        1.97| 542|      0.68|      0.88|   59823|    74.76|    97.15|        1|   F|ARTHAUD|Nathalie| 385|      0.48|      0.64|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 04|  Alpes-de-Haute-Pr...|                         1|         1ère circonscription|    Complet|   61692|      13750|    22.29|  47942|    77.71|   691|        1.12|        1.44| 315|      0.51|      0.66|   46936|    76.08|     97.9|        1|   F|ARTHAUD|Nathalie| 275|      0.45|      0.59|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 04|  Alpes-de-Haute-Pr...|                         2|         2ème circonscription|    Complet|   66383|      15540|    23.41|  50843|    76.59|   787|        1.19|        1.55| 309|      0.47|      0.61|   49747|    74.94|    97.84|        1|   F|ARTHAUD|Nathalie| 230|      0.35|      0.46|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 05|          Hautes-Alpes|                         1|         1ère circonscription|    Complet|   59486|      13601|    22.86|  45885|    77.14|   731|        1.23|        1.59| 287|      0.48|      0.63|   44867|    75.42|    97.78|        1|   F|ARTHAUD|Nathalie| 234|      0.39|      0.52|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 05|          Hautes-Alpes|                         2|         2ème circonscription|    Complet|   54033|      11756|    21.76|  42277|    78.24|   664|        1.23|        1.57| 245|      0.45|      0.58|   41368|    76.56|    97.85|        1|   F|ARTHAUD|Nathalie| 194|      0.36|      0.47|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 06|       Alpes-Maritimes|                         1|         1ère circonscription|    Complet|   81800|      24731|    30.23|  57069|    69.77|   603|        0.74|        1.06| 354|      0.43|      0.62|   56112|     68.6|    98.32|        1|   F|ARTHAUD|Nathalie| 166|       0.2|       0.3|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 06|       Alpes-Maritimes|                         2|         2ème circonscription|    Complet|   88918|      22495|     25.3|  66423|     74.7|   949|        1.07|        1.43| 341|      0.38|      0.51|   65133|    73.25|    98.06|        1|   F|ARTHAUD|Nathalie| 216|      0.24|      0.33|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - |                 06|       Alpes-Maritimes|                         3|         3ème circonscription|    Complet|   90956|      26607|    29.25|  64349|    70.75|   789|        0.87|        1.23| 342|      0.38|      0.53|   63218|     69.5|    98.24|        1|   F|ARTHAUD|Nathalie| 206|      0.23|      0.33|
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - +-------------------+----------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - only showing top 20 rows
[2022-12-30T00:07:14.482+0100] {spark_submit.py:495} INFO - 
[2022-12-30T00:07:14.695+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T00:07:14.695+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T00:07:14.697+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T00:07:14.788+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.2.15:45963 in memory (size: 9.9 KiB, free: 413.8 MiB)
[2022-12-30T00:07:14.888+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:14 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T00:07:15.065+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO CodeGenerator: Code generated in 126.903243 ms
[2022-12-30T00:07:15.073+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 199.4 KiB, free 413.0 MiB)
[2022-12-30T00:07:15.089+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 413.0 MiB)
[2022-12-30T00:07:15.093+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.2.15:45963 (size: 34.0 KiB, free: 413.8 MiB)
[2022-12-30T00:07:15.095+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:15.100+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T00:07:15.175+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2022-12-30T00:07:15.180+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:15.180+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:15.181+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T00:07:15.181+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:15.193+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:15.236+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 57.4 KiB, free 412.9 MiB)
[2022-12-30T00:07:15.238+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 412.9 MiB)
[2022-12-30T00:07:15.239+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.2.15:45963 (size: 22.0 KiB, free: 413.8 MiB)
[2022-12-30T00:07:15.240+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:15.242+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:15.247+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2022-12-30T00:07:15.250+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:15.251+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
[2022-12-30T00:07:15.365+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO CodeGenerator: Code generated in 53.958014 ms
[2022-12-30T00:07:15.400+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO CodeGenerator: Code generated in 9.899986 ms
[2022-12-30T00:07:15.460+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO CodeGenerator: Code generated in 33.868789 ms
[2022-12-30T00:07:15.476+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T00:07:15.896+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.2.15:45963 in memory (size: 5.9 KiB, free: 413.8 MiB)
[2022-12-30T00:07:15.929+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.2.15:45963 in memory (size: 34.0 KiB, free: 413.8 MiB)
[2022-12-30T00:07:15.957+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.2.15:45963 in memory (size: 34.0 KiB, free: 413.8 MiB)
[2022-12-30T00:07:15.978+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:15 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.2.15:45963 in memory (size: 34.0 KiB, free: 413.9 MiB)
[2022-12-30T00:07:16.114+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2810 bytes result sent to driver
[2022-12-30T00:07:16.122+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 872 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:16.126+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0,925 s
[2022-12-30T00:07:16.128+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T00:07:16.129+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: running: Set()
[2022-12-30T00:07:16.129+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: waiting: Set()
[2022-12-30T00:07:16.130+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: failed: Set()
[2022-12-30T00:07:16.131+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2022-12-30T00:07:16.184+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T00:07:16.278+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T00:07:16.367+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO CodeGenerator: Code generated in 48.412567 ms
[2022-12-30T00:07:16.433+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2022-12-30T00:07:16.434+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:16.435+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:16.435+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2022-12-30T00:07:16.435+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:16.438+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:16.493+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 62.1 KiB, free 413.6 MiB)
[2022-12-30T00:07:16.501+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 413.5 MiB)
[2022-12-30T00:07:16.503+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.2.15:45963 (size: 23.7 KiB, free: 413.8 MiB)
[2022-12-30T00:07:16.507+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:16.508+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:16.509+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2022-12-30T00:07:16.515+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:16.516+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
[2022-12-30T00:07:16.618+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T00:07:16.620+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 31 ms
[2022-12-30T00:07:16.739+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 4309 bytes result sent to driver
[2022-12-30T00:07:16.745+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 228 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:16.745+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2022-12-30T00:07:16.745+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0,266 s
[2022-12-30T00:07:16.745+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T00:07:16.745+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: running: Set()
[2022-12-30T00:07:16.745+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: waiting: Set()
[2022-12-30T00:07:16.745+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: failed: Set()
[2022-12-30T00:07:16.798+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.2.15:45963 in memory (size: 23.7 KiB, free: 413.9 MiB)
[2022-12-30T00:07:16.831+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO CodeGenerator: Code generated in 25.232262 ms
[2022-12-30T00:07:16.860+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:16.862+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:16.862+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:16.862+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2022-12-30T00:07:16.862+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:16.865+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:16.869+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.1 KiB, free 413.6 MiB)
[2022-12-30T00:07:16.872+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 413.6 MiB)
[2022-12-30T00:07:16.873+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.2.15:45963 (size: 5.5 KiB, free: 413.9 MiB)
[2022-12-30T00:07:16.873+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:16.876+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:16.877+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2022-12-30T00:07:16.878+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:16.878+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO Executor: Running task 0.0 in stage 8.0 (TID 5)
[2022-12-30T00:07:16.883+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T00:07:16.885+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2022-12-30T00:07:16.896+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO Executor: Finished task 0.0 in stage 8.0 (TID 5). 2656 bytes result sent to driver
[2022-12-30T00:07:16.901+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 19 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:16.901+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2022-12-30T00:07:16.901+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0,032 s
[2022-12-30T00:07:16.901+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T00:07:16.901+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2022-12-30T00:07:16.901+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:16 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0,039210 s
[2022-12-30T00:07:16.913+0100] {spark_submit.py:495} INFO - ************Distinct count**************** :577
[2022-12-30T00:07:17.032+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T00:07:17.033+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T00:07:17.033+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T00:07:17.122+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T00:07:17.149+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 199.4 KiB, free 413.4 MiB)
[2022-12-30T00:07:17.164+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 413.4 MiB)
[2022-12-30T00:07:17.165+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.2.15:45963 (size: 34.0 KiB, free: 413.8 MiB)
[2022-12-30T00:07:17.167+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO SparkContext: Created broadcast 10 from showString at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:17.173+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T00:07:17.190+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Registering RDD 27 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2022-12-30T00:07:17.190+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Got map stage job 6 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:17.190+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:17.190+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T00:07:17.190+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:17.192+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:17.200+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 57.4 KiB, free 413.3 MiB)
[2022-12-30T00:07:17.208+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 413.3 MiB)
[2022-12-30T00:07:17.209+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.2.15:45963 (size: 22.0 KiB, free: 413.8 MiB)
[2022-12-30T00:07:17.216+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:17.219+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:17.220+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2022-12-30T00:07:17.221+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:17.222+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO Executor: Running task 0.0 in stage 9.0 (TID 6)
[2022-12-30T00:07:17.270+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T00:07:17.393+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.2.15:45963 in memory (size: 5.5 KiB, free: 413.8 MiB)
[2022-12-30T00:07:17.472+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO Executor: Finished task 0.0 in stage 9.0 (TID 6). 2767 bytes result sent to driver
[2022-12-30T00:07:17.475+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 252 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:17.475+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2022-12-30T00:07:17.476+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0) finished in 0,283 s
[2022-12-30T00:07:17.476+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T00:07:17.476+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: running: Set()
[2022-12-30T00:07:17.476+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: waiting: Set()
[2022-12-30T00:07:17.476+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: failed: Set()
[2022-12-30T00:07:17.481+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T00:07:17.505+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T00:07:17.579+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO CodeGenerator: Code generated in 57.804094 ms
[2022-12-30T00:07:17.614+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:17.616+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:17.616+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Final stage: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:17.616+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2022-12-30T00:07:17.616+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:17.619+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[30] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:17.644+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 73.4 KiB, free 413.2 MiB)
[2022-12-30T00:07:17.648+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 413.2 MiB)
[2022-12-30T00:07:17.649+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.2.15:45963 (size: 25.7 KiB, free: 413.8 MiB)
[2022-12-30T00:07:17.649+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:17.651+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[30] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:17.651+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2022-12-30T00:07:17.653+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 7) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:17.653+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO Executor: Running task 0.0 in stage 11.0 (TID 7)
[2022-12-30T00:07:17.663+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T00:07:17.672+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2022-12-30T00:07:17.732+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO Executor: Finished task 0.0 in stage 11.0 (TID 7). 7622 bytes result sent to driver
[2022-12-30T00:07:17.737+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 7) in 81 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:17.738+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2022-12-30T00:07:17.738+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0) finished in 0,100 s
[2022-12-30T00:07:17.738+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T00:07:17.738+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2022-12-30T00:07:17.738+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 0,121282 s
[2022-12-30T00:07:17.760+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.2.15:45963 in memory (size: 25.7 KiB, free: 413.8 MiB)
[2022-12-30T00:07:17.770+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T00:07:17.770+0100] {spark_submit.py:495} INFO - |Code du département|Libellé du département         |Code de la circonscription|Libellé de la circonscription|Etat saisie|Inscrits|Abstentions|% Abs/Ins|Votants|% Vot/Ins|Blancs|% Blancs/Ins|% Blancs/Vot|Nuls|% Nuls/Ins|% Nuls/Vot|Exprimés|% Exp/Ins|% Exp/Vot|N°Panneau|Sexe|Nom    |Prénom  |Voix|% Voix/Ins|% Voix/Exp|
[2022-12-30T00:07:17.770+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T00:07:17.770+0100] {spark_submit.py:495} INFO - |06                 |Alpes-Maritimes                |5                         |5ème circonscription         |Complet    |90651   |24266      |26.77    |66385  |73.23    |847   |0.93        |1.28        |843 |0.93      |1.27      |64695   |71.37    |97.45    |1        |F   |ARTHAUD|Nathalie|196 |0.22      |0.3       |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |ZZ                 |Français établis hors de France|10                        |10ème circonscription        |Complet    |103910  |63575      |61.18    |40335  |38.82    |365   |0.35        |0.9         |191 |0.18      |0.47      |39779   |38.28    |98.62    |1        |F   |ARTHAUD|Nathalie|90  |0.09      |0.23      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |24                 |Dordogne                       |2                         |2ème circonscription         |Complet    |84067   |18394      |21.88    |65673  |78.12    |832   |0.99        |1.27        |580 |0.69      |0.88      |64261   |76.44    |97.85    |1        |F   |ARTHAUD|Nathalie|314 |0.37      |0.49      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |2                         |2ème circonscription         |Complet    |85933   |16008      |18.63    |69925  |81.37    |877   |1.02        |1.25        |287 |0.33      |0.41      |68761   |80.02    |98.34    |1        |F   |ARTHAUD|Nathalie|220 |0.26      |0.32      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |ZB                 |Martinique                     |1                         |1ère circonscription         |Complet    |80037   |44808      |55.98    |35229  |44.02    |1154  |1.44        |3.28        |823 |1.03      |2.34      |33252   |41.55    |94.39    |1        |F   |ARTHAUD|Nathalie|432 |0.54      |1.3       |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |ZC                 |Guyane                         |1                         |1ère circonscription         |Complet    |56628   |32823      |57.96    |23805  |42.04    |556   |0.98        |2.34        |377 |0.67      |1.58      |22872   |40.39    |96.08    |1        |F   |ARTHAUD|Nathalie|176 |0.31      |0.77      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |01                 |Ain                            |1                         |1ère circonscription         |Complet    |85723   |18592      |21.69    |67131  |78.31    |1154  |1.35        |1.72        |393 |0.46      |0.59      |65584   |76.51    |97.7     |1        |F   |ARTHAUD|Nathalie|317 |0.37      |0.48      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |61                 |Orne                           |2                         |2ème circonscription         |Complet    |66030   |16122      |24.42    |49908  |75.58    |817   |1.24        |1.64        |278 |0.42      |0.56      |48813   |73.93    |97.81    |1        |F   |ARTHAUD|Nathalie|330 |0.5       |0.68      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |11                        |11ème circonscription        |Complet    |68878   |16249      |23.59    |52629  |76.41    |692   |1.0         |1.31        |318 |0.46      |0.6       |51619   |74.94    |98.08    |1        |F   |ARTHAUD|Nathalie|227 |0.33      |0.44      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |12                        |12ème circonscription        |Complet    |70828   |15015      |21.2     |55813  |78.8     |815   |1.15        |1.46        |233 |0.33      |0.42      |54765   |77.32    |98.12    |1        |F   |ARTHAUD|Nathalie|222 |0.31      |0.41      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |50                 |Manche                         |2                         |2ème circonscription         |Complet    |96973   |22676      |23.38    |74297  |76.62    |1262  |1.3         |1.7         |607 |0.63      |0.82      |72428   |74.69    |97.48    |1        |F   |ARTHAUD|Nathalie|524 |0.54      |0.72      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |9                         |9ème circonscription         |Complet    |92669   |21481      |23.18    |71188  |76.82    |1021  |1.1         |1.43        |361 |0.39      |0.51      |69806   |75.33    |98.06    |1        |F   |ARTHAUD|Nathalie|366 |0.39      |0.52      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |92                 |Hauts-de-Seine                 |2                         |2ème circonscription         |Complet    |69068   |13416      |19.42    |55652  |80.58    |795   |1.15        |1.43        |216 |0.31      |0.39      |54641   |79.11    |98.18    |1        |F   |ARTHAUD|Nathalie|169 |0.24      |0.31      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |60                 |Oise                           |2                         |2ème circonscription         |Complet    |88749   |21439      |24.16    |67310  |75.84    |1016  |1.14        |1.51        |1150|1.3       |1.71      |65144   |73.4     |96.78    |1        |F   |ARTHAUD|Nathalie|475 |0.54      |0.73      |
[2022-12-30T00:07:17.771+0100] {spark_submit.py:495} INFO - |13                 |Bouches-du-Rhône               |10                        |10ème circonscription        |Complet    |108586  |24129      |22.22    |84457  |77.78    |1235  |1.14        |1.46        |448 |0.41      |0.53      |82774   |76.23    |98.01    |1        |F   |ARTHAUD|Nathalie|269 |0.25      |0.32      |
[2022-12-30T00:07:17.772+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |1                         |1ère circonscription         |Complet    |97799   |19432      |19.87    |78367  |80.13    |898   |0.92        |1.15        |416 |0.43      |0.53      |77053   |78.79    |98.32    |1        |F   |ARTHAUD|Nathalie|183 |0.19      |0.24      |
[2022-12-30T00:07:17.772+0100] {spark_submit.py:495} INFO - |91                 |Essonne                        |9                         |9ème circonscription         |Complet    |78393   |18934      |24.15    |59459  |75.85    |870   |1.11        |1.46        |335 |0.43      |0.56      |58254   |74.31    |97.97    |1        |F   |ARTHAUD|Nathalie|265 |0.34      |0.45      |
[2022-12-30T00:07:17.772+0100] {spark_submit.py:495} INFO - |14                 |Calvados                       |6                         |6ème circonscription         |Complet    |95726   |21470      |22.43    |74256  |77.57    |1179  |1.23        |1.59        |589 |0.62      |0.79      |72488   |75.72    |97.62    |1        |F   |ARTHAUD|Nathalie|581 |0.61      |0.8       |
[2022-12-30T00:07:17.772+0100] {spark_submit.py:495} INFO - |22                 |Côtes-d'Armor                  |3                         |3ème circonscription         |Complet    |88709   |17554      |19.79    |71155  |80.21    |1189  |1.34        |1.67        |645 |0.73      |0.91      |69321   |78.14    |97.42    |1        |F   |ARTHAUD|Nathalie|521 |0.59      |0.75      |
[2022-12-30T00:07:17.772+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |10                        |10ème circonscription        |Complet    |69820   |15846      |22.7     |53974  |77.3     |641   |0.92        |1.19        |233 |0.33      |0.43      |53100   |76.05    |98.38    |1        |F   |ARTHAUD|Nathalie|206 |0.3       |0.39      |
[2022-12-30T00:07:17.772+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T00:07:17.772+0100] {spark_submit.py:495} INFO - only showing top 20 rows
[2022-12-30T00:07:17.772+0100] {spark_submit.py:495} INFO - 
[2022-12-30T00:07:17.844+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T00:07:17.845+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T00:07:17.845+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T00:07:17.895+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T00:07:17.920+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 199.4 KiB, free 413.1 MiB)
[2022-12-30T00:07:17.933+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 413.1 MiB)
[2022-12-30T00:07:17.934+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.2.15:45963 (size: 34.0 KiB, free: 413.8 MiB)
[2022-12-30T00:07:17.934+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO SparkContext: Created broadcast 13 from count at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:17.941+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T00:07:17.957+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2022-12-30T00:07:17.957+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Got map stage job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:17.957+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:17.957+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T00:07:17.957+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:17.960+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:17.963+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 57.4 KiB, free 413.0 MiB)
[2022-12-30T00:07:17.964+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 413.0 MiB)
[2022-12-30T00:07:17.965+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.2.15:45963 (size: 22.0 KiB, free: 413.8 MiB)
[2022-12-30T00:07:17.965+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:17.966+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:17.966+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2022-12-30T00:07:17.968+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 8) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:17.968+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:17 INFO Executor: Running task 0.0 in stage 12.0 (TID 8)
[2022-12-30T00:07:18.008+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T00:07:18.137+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO Executor: Finished task 0.0 in stage 12.0 (TID 8). 2767 bytes result sent to driver
[2022-12-30T00:07:18.140+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 8) in 171 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:18.141+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2022-12-30T00:07:18.141+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0,180 s
[2022-12-30T00:07:18.141+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T00:07:18.141+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: running: Set()
[2022-12-30T00:07:18.141+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: waiting: Set()
[2022-12-30T00:07:18.141+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: failed: Set()
[2022-12-30T00:07:18.146+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T00:07:18.163+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T00:07:18.193+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Registering RDD 37 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2022-12-30T00:07:18.194+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Got map stage job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:18.194+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:18.194+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2022-12-30T00:07:18.194+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:18.198+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:18.214+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 62.1 KiB, free 412.9 MiB)
[2022-12-30T00:07:18.216+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 412.9 MiB)
[2022-12-30T00:07:18.217+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.2.15:45963 (size: 23.7 KiB, free: 413.7 MiB)
[2022-12-30T00:07:18.218+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:18.219+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:18.220+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2022-12-30T00:07:18.221+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 9) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:18.222+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO Executor: Running task 0.0 in stage 14.0 (TID 9)
[2022-12-30T00:07:18.237+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T00:07:18.237+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
[2022-12-30T00:07:18.262+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO Executor: Finished task 0.0 in stage 14.0 (TID 9). 4309 bytes result sent to driver
[2022-12-30T00:07:18.266+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 9) in 42 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:18.266+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2022-12-30T00:07:18.266+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0,061 s
[2022-12-30T00:07:18.266+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T00:07:18.266+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: running: Set()
[2022-12-30T00:07:18.266+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: waiting: Set()
[2022-12-30T00:07:18.266+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: failed: Set()
[2022-12-30T00:07:18.323+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:18.330+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:18.330+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Final stage: ResultStage 17 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:18.330+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
[2022-12-30T00:07:18.330+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:18.333+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:18.335+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 11.1 KiB, free 412.9 MiB)
[2022-12-30T00:07:18.338+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 412.9 MiB)
[2022-12-30T00:07:18.344+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.2.15:45963 (size: 5.5 KiB, free: 413.7 MiB)
[2022-12-30T00:07:18.345+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:18.346+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:18.346+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2022-12-30T00:07:18.348+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 10) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:18.348+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO Executor: Running task 0.0 in stage 17.0 (TID 10)
[2022-12-30T00:07:18.351+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T00:07:18.353+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2022-12-30T00:07:18.356+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO Executor: Finished task 0.0 in stage 17.0 (TID 10). 2656 bytes result sent to driver
[2022-12-30T00:07:18.358+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 10) in 10 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:18.358+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2022-12-30T00:07:18.359+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: ResultStage 17 (count at NativeMethodAccessorImpl.java:0) finished in 0,025 s
[2022-12-30T00:07:18.360+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T00:07:18.361+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
[2022-12-30T00:07:18.371+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0,032955 s
[2022-12-30T00:07:18.372+0100] {spark_submit.py:495} INFO - ****************Distinct count drop******************* :577
[2022-12-30T00:07:18.454+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T00:07:18.455+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T00:07:18.455+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T00:07:18.521+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T00:07:18.545+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 199.4 KiB, free 412.7 MiB)
[2022-12-30T00:07:18.578+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.2.15:45963 in memory (size: 23.7 KiB, free: 413.8 MiB)
[2022-12-30T00:07:18.589+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 412.8 MiB)
[2022-12-30T00:07:18.589+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.2.15:45963 (size: 34.0 KiB, free: 413.7 MiB)
[2022-12-30T00:07:18.591+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO SparkContext: Created broadcast 17 from showString at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:18.593+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T00:07:18.613+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Registering RDD 44 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2022-12-30T00:07:18.613+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Got map stage job 11 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:18.613+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Final stage: ShuffleMapStage 18 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:18.613+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T00:07:18.613+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:18.619+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[44] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:18.622+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.2.15:45963 in memory (size: 5.5 KiB, free: 413.7 MiB)
[2022-12-30T00:07:18.646+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 57.4 KiB, free 412.7 MiB)
[2022-12-30T00:07:18.646+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 412.7 MiB)
[2022-12-30T00:07:18.646+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.2.15:45963 (size: 22.0 KiB, free: 413.7 MiB)
[2022-12-30T00:07:18.647+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:18.648+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[44] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:18.648+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2022-12-30T00:07:18.649+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 11) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:18.650+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO Executor: Running task 0.0 in stage 18.0 (TID 11)
[2022-12-30T00:07:18.675+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T00:07:18.790+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO Executor: Finished task 0.0 in stage 18.0 (TID 11). 2724 bytes result sent to driver
[2022-12-30T00:07:18.795+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 11) in 142 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:18.795+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2022-12-30T00:07:18.795+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: ShuffleMapStage 18 (showString at NativeMethodAccessorImpl.java:0) finished in 0,173 s
[2022-12-30T00:07:18.795+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T00:07:18.796+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: running: Set()
[2022-12-30T00:07:18.796+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: waiting: Set()
[2022-12-30T00:07:18.796+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: failed: Set()
[2022-12-30T00:07:18.799+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T00:07:18.825+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T00:07:18.845+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.2.15:45963 in memory (size: 22.0 KiB, free: 413.7 MiB)
[2022-12-30T00:07:18.874+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-12-30T00:07:18.875+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Got job 12 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T00:07:18.875+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Final stage: ResultStage 20 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T00:07:18.875+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2022-12-30T00:07:18.875+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Missing parents: List()
[2022-12-30T00:07:18.878+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T00:07:18.889+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 73.4 KiB, free 412.7 MiB)
[2022-12-30T00:07:18.891+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 25.6 KiB, free 412.7 MiB)
[2022-12-30T00:07:18.892+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.2.15:45963 (size: 25.6 KiB, free: 413.7 MiB)
[2022-12-30T00:07:18.892+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513
[2022-12-30T00:07:18.893+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T00:07:18.893+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2022-12-30T00:07:18.895+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 12) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T00:07:18.895+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO Executor: Running task 0.0 in stage 20.0 (TID 12)
[2022-12-30T00:07:18.905+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T00:07:18.905+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2022-12-30T00:07:18.931+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO Executor: Finished task 0.0 in stage 20.0 (TID 12). 7622 bytes result sent to driver
[2022-12-30T00:07:18.940+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 12) in 39 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T00:07:18.940+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2022-12-30T00:07:18.940+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: ResultStage 20 (showString at NativeMethodAccessorImpl.java:0) finished in 0,056 s
[2022-12-30T00:07:18.940+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T00:07:18.940+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2022-12-30T00:07:18.940+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:18 INFO DAGScheduler: Job 12 finished: showString at NativeMethodAccessorImpl.java:0, took 0,061339 s
[2022-12-30T00:07:18.964+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T00:07:18.964+0100] {spark_submit.py:495} INFO - |Code du département|Libellé du département         |Code de la circonscription|Libellé de la circonscription|Etat saisie|Inscrits|Abstentions|% Abs/Ins|Votants|% Vot/Ins|Blancs|% Blancs/Ins|% Blancs/Vot|Nuls|% Nuls/Ins|% Nuls/Vot|Exprimés|% Exp/Ins|% Exp/Vot|N°Panneau|Sexe|Nom    |Prénom  |Voix|% Voix/Ins|% Voix/Exp|
[2022-12-30T00:07:18.964+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T00:07:18.964+0100] {spark_submit.py:495} INFO - |06                 |Alpes-Maritimes                |5                         |5ème circonscription         |Complet    |90651   |24266      |26.77    |66385  |73.23    |847   |0.93        |1.28        |843 |0.93      |1.27      |64695   |71.37    |97.45    |1        |F   |ARTHAUD|Nathalie|196 |0.22      |0.3       |
[2022-12-30T00:07:18.964+0100] {spark_submit.py:495} INFO - |ZZ                 |Français établis hors de France|10                        |10ème circonscription        |Complet    |103910  |63575      |61.18    |40335  |38.82    |365   |0.35        |0.9         |191 |0.18      |0.47      |39779   |38.28    |98.62    |1        |F   |ARTHAUD|Nathalie|90  |0.09      |0.23      |
[2022-12-30T00:07:18.964+0100] {spark_submit.py:495} INFO - |24                 |Dordogne                       |2                         |2ème circonscription         |Complet    |84067   |18394      |21.88    |65673  |78.12    |832   |0.99        |1.27        |580 |0.69      |0.88      |64261   |76.44    |97.85    |1        |F   |ARTHAUD|Nathalie|314 |0.37      |0.49      |
[2022-12-30T00:07:18.964+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |2                         |2ème circonscription         |Complet    |85933   |16008      |18.63    |69925  |81.37    |877   |1.02        |1.25        |287 |0.33      |0.41      |68761   |80.02    |98.34    |1        |F   |ARTHAUD|Nathalie|220 |0.26      |0.32      |
[2022-12-30T00:07:18.964+0100] {spark_submit.py:495} INFO - |ZB                 |Martinique                     |1                         |1ère circonscription         |Complet    |80037   |44808      |55.98    |35229  |44.02    |1154  |1.44        |3.28        |823 |1.03      |2.34      |33252   |41.55    |94.39    |1        |F   |ARTHAUD|Nathalie|432 |0.54      |1.3       |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |ZC                 |Guyane                         |1                         |1ère circonscription         |Complet    |56628   |32823      |57.96    |23805  |42.04    |556   |0.98        |2.34        |377 |0.67      |1.58      |22872   |40.39    |96.08    |1        |F   |ARTHAUD|Nathalie|176 |0.31      |0.77      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |01                 |Ain                            |1                         |1ère circonscription         |Complet    |85723   |18592      |21.69    |67131  |78.31    |1154  |1.35        |1.72        |393 |0.46      |0.59      |65584   |76.51    |97.7     |1        |F   |ARTHAUD|Nathalie|317 |0.37      |0.48      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |61                 |Orne                           |2                         |2ème circonscription         |Complet    |66030   |16122      |24.42    |49908  |75.58    |817   |1.24        |1.64        |278 |0.42      |0.56      |48813   |73.93    |97.81    |1        |F   |ARTHAUD|Nathalie|330 |0.5       |0.68      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |11                        |11ème circonscription        |Complet    |68878   |16249      |23.59    |52629  |76.41    |692   |1.0         |1.31        |318 |0.46      |0.6       |51619   |74.94    |98.08    |1        |F   |ARTHAUD|Nathalie|227 |0.33      |0.44      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |12                        |12ème circonscription        |Complet    |70828   |15015      |21.2     |55813  |78.8     |815   |1.15        |1.46        |233 |0.33      |0.42      |54765   |77.32    |98.12    |1        |F   |ARTHAUD|Nathalie|222 |0.31      |0.41      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |50                 |Manche                         |2                         |2ème circonscription         |Complet    |96973   |22676      |23.38    |74297  |76.62    |1262  |1.3         |1.7         |607 |0.63      |0.82      |72428   |74.69    |97.48    |1        |F   |ARTHAUD|Nathalie|524 |0.54      |0.72      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |9                         |9ème circonscription         |Complet    |92669   |21481      |23.18    |71188  |76.82    |1021  |1.1         |1.43        |361 |0.39      |0.51      |69806   |75.33    |98.06    |1        |F   |ARTHAUD|Nathalie|366 |0.39      |0.52      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |92                 |Hauts-de-Seine                 |2                         |2ème circonscription         |Complet    |69068   |13416      |19.42    |55652  |80.58    |795   |1.15        |1.43        |216 |0.31      |0.39      |54641   |79.11    |98.18    |1        |F   |ARTHAUD|Nathalie|169 |0.24      |0.31      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |60                 |Oise                           |2                         |2ème circonscription         |Complet    |88749   |21439      |24.16    |67310  |75.84    |1016  |1.14        |1.51        |1150|1.3       |1.71      |65144   |73.4     |96.78    |1        |F   |ARTHAUD|Nathalie|475 |0.54      |0.73      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |13                 |Bouches-du-Rhône               |10                        |10ème circonscription        |Complet    |108586  |24129      |22.22    |84457  |77.78    |1235  |1.14        |1.46        |448 |0.41      |0.53      |82774   |76.23    |98.01    |1        |F   |ARTHAUD|Nathalie|269 |0.25      |0.32      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |1                         |1ère circonscription         |Complet    |97799   |19432      |19.87    |78367  |80.13    |898   |0.92        |1.15        |416 |0.43      |0.53      |77053   |78.79    |98.32    |1        |F   |ARTHAUD|Nathalie|183 |0.19      |0.24      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |91                 |Essonne                        |9                         |9ème circonscription         |Complet    |78393   |18934      |24.15    |59459  |75.85    |870   |1.11        |1.46        |335 |0.43      |0.56      |58254   |74.31    |97.97    |1        |F   |ARTHAUD|Nathalie|265 |0.34      |0.45      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |14                 |Calvados                       |6                         |6ème circonscription         |Complet    |95726   |21470      |22.43    |74256  |77.57    |1179  |1.23        |1.59        |589 |0.62      |0.79      |72488   |75.72    |97.62    |1        |F   |ARTHAUD|Nathalie|581 |0.61      |0.8       |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |22                 |Côtes-d'Armor                  |3                         |3ème circonscription         |Complet    |88709   |17554      |19.79    |71155  |80.21    |1189  |1.34        |1.67        |645 |0.73      |0.91      |69321   |78.14    |97.42    |1        |F   |ARTHAUD|Nathalie|521 |0.59      |0.75      |
[2022-12-30T00:07:18.965+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |10                        |10ème circonscription        |Complet    |69820   |15846      |22.7     |53974  |77.3     |641   |0.92        |1.19        |233 |0.33      |0.43      |53100   |76.05    |98.38    |1        |F   |ARTHAUD|Nathalie|206 |0.3       |0.39      |
[2022-12-30T00:07:18.966+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T00:07:18.966+0100] {spark_submit.py:495} INFO - only showing top 20 rows
[2022-12-30T00:07:18.966+0100] {spark_submit.py:495} INFO - 
[2022-12-30T00:07:19.018+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO SparkContext: Invoking stop() from shutdown hook
[2022-12-30T00:07:19.053+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO SparkUI: Stopped Spark web UI at http://10.0.2.15:4040
[2022-12-30T00:07:19.084+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2022-12-30T00:07:19.113+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO MemoryStore: MemoryStore cleared
[2022-12-30T00:07:19.117+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO BlockManager: BlockManager stopped
[2022-12-30T00:07:19.122+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO BlockManagerMaster: BlockManagerMaster stopped
[2022-12-30T00:07:19.125+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2022-12-30T00:07:19.139+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO SparkContext: Successfully stopped SparkContext
[2022-12-30T00:07:19.139+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO ShutdownHookManager: Shutdown hook called
[2022-12-30T00:07:19.139+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-495bbaff-a1c3-433a-85f9-300c9ba5c026
[2022-12-30T00:07:19.145+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-04101050-60d8-40bd-993f-361f0592db0f
[2022-12-30T00:07:19.153+0100] {spark_submit.py:495} INFO - 22/12/30 00:07:19 INFO ShutdownHookManager: Deleting directory /tmp/spark-04101050-60d8-40bd-993f-361f0592db0f/pyspark-b42527d6-8ecb-4b30-a100-5a93225a93eb
[2022-12-30T00:07:19.199+0100] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=spark_airflow_project, task_id=python_job, execution_date=20221229T230140, start_date=20221229T230657, end_date=20221229T230719
[2022-12-30T00:07:19.219+0100] {local_task_job.py:159} INFO - Task exited with return code 0
[2022-12-30T00:07:19.226+0100] {taskinstance.py:2582} INFO - 0 downstream tasks scheduled from follow-on schedule check
