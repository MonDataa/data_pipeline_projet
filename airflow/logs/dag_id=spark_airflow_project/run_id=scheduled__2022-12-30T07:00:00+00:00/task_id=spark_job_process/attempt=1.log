[2022-12-30T09:07:50.017+0100] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: spark_airflow_project.spark_job_process scheduled__2022-12-30T07:00:00+00:00 [queued]>
[2022-12-30T09:07:50.027+0100] {taskinstance.py:1087} INFO - Dependencies all met for <TaskInstance: spark_airflow_project.spark_job_process scheduled__2022-12-30T07:00:00+00:00 [queued]>
[2022-12-30T09:07:50.027+0100] {taskinstance.py:1283} INFO - 
--------------------------------------------------------------------------------
[2022-12-30T09:07:50.027+0100] {taskinstance.py:1284} INFO - Starting attempt 1 of 4
[2022-12-30T09:07:50.027+0100] {taskinstance.py:1285} INFO - 
--------------------------------------------------------------------------------
[2022-12-30T09:07:50.072+0100] {taskinstance.py:1304} INFO - Executing <Task(SparkSubmitOperator): spark_job_process> on 2022-12-30 07:00:00+00:00
[2022-12-30T09:07:50.076+0100] {standard_task_runner.py:55} INFO - Started process 15727 to run task
[2022-12-30T09:07:50.082+0100] {standard_task_runner.py:82} INFO - Running: ['airflow', 'tasks', 'run', 'spark_airflow_project', 'spark_job_process', 'scheduled__2022-12-30T07:00:00+00:00', '--job-id', '79', '--raw', '--subdir', 'DAGS_FOLDER/spark_airflow.py', '--cfg-path', '/tmp/tmpktttrarx']
[2022-12-30T09:07:50.084+0100] {standard_task_runner.py:83} INFO - Job 79: Subtask spark_job_process
[2022-12-30T09:07:50.181+0100] {task_command.py:389} INFO - Running <TaskInstance: spark_airflow_project.spark_job_process scheduled__2022-12-30T07:00:00+00:00 [running]> on host momo-VirtualBox
[2022-12-30T09:07:50.229+0100] {taskinstance.py:1511} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=Ranga
AIRFLOW_CTX_DAG_ID=spark_airflow_project
AIRFLOW_CTX_TASK_ID=spark_job_process
AIRFLOW_CTX_EXECUTION_DATE=2022-12-30T07:00:00+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2022-12-30T07:00:00+00:00
[2022-12-30T09:07:50.237+0100] {base.py:73} INFO - Using connection ID 'spark_default' for task execution.
[2022-12-30T09:07:50.238+0100] {spark_submit.py:344} INFO - Spark-Submit cmd: spark-submit --master spark://momo-VirtualBox:7077 --name arrow-spark --queue root.default /home/momo/Bureau/spark_d2.py
[2022-12-30T09:07:56.852+0100] {spark_submit.py:495} INFO - 22/12/30 09:07:56 WARN Utils: Your hostname, momo-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
[2022-12-30T09:07:56.888+0100] {spark_submit.py:495} INFO - 22/12/30 09:07:56 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address
[2022-12-30T09:08:01.619+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:01 INFO SparkContext: Running Spark version 3.3.1
[2022-12-30T09:08:01.925+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2022-12-30T09:08:02.263+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO ResourceUtils: ==============================================================
[2022-12-30T09:08:02.263+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO ResourceUtils: No custom resources configured for spark.driver.
[2022-12-30T09:08:02.264+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO ResourceUtils: ==============================================================
[2022-12-30T09:08:02.264+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO SparkContext: Submitted application: conf pro spark
[2022-12-30T09:08:02.376+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2022-12-30T09:08:02.406+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO ResourceProfile: Limiting resource is cpu
[2022-12-30T09:08:02.407+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2022-12-30T09:08:02.739+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO SecurityManager: Changing view acls to: momo
[2022-12-30T09:08:02.743+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO SecurityManager: Changing modify acls to: momo
[2022-12-30T09:08:02.754+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO SecurityManager: Changing view acls groups to:
[2022-12-30T09:08:02.755+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO SecurityManager: Changing modify acls groups to:
[2022-12-30T09:08:02.756+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:02 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(momo); groups with view permissions: Set(); users  with modify permissions: Set(momo); groups with modify permissions: Set()
[2022-12-30T09:08:03.796+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:03 INFO Utils: Successfully started service 'sparkDriver' on port 33581.
[2022-12-30T09:08:03.931+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:03 INFO SparkEnv: Registering MapOutputTracker
[2022-12-30T09:08:04.078+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:04 INFO SparkEnv: Registering BlockManagerMaster
[2022-12-30T09:08:04.145+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:04 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2022-12-30T09:08:04.145+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:04 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2022-12-30T09:08:04.152+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:04 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2022-12-30T09:08:04.227+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:04 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-fa4c926a-7eaf-4b67-8571-98e3733245e2
[2022-12-30T09:08:04.286+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:04 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2022-12-30T09:08:04.343+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:04 INFO SparkEnv: Registering OutputCommitCoordinator
[2022-12-30T09:08:05.429+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:05 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
[2022-12-30T09:08:05.469+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:05 INFO Utils: Successfully started service 'SparkUI' on port 4041.
[2022-12-30T09:08:05.994+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:05 INFO Executor: Starting executor ID driver on host 10.0.2.15
[2022-12-30T09:08:06.050+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:06 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2022-12-30T09:08:06.266+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:06 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37791.
[2022-12-30T09:08:06.266+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:06 INFO NettyBlockTransferService: Server created on 10.0.2.15:37791
[2022-12-30T09:08:06.274+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:06 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2022-12-30T09:08:06.285+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:06 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.2.15, 37791, None)
[2022-12-30T09:08:06.304+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:06 INFO BlockManagerMasterEndpoint: Registering block manager 10.0.2.15:37791 with 434.4 MiB RAM, BlockManagerId(driver, 10.0.2.15, 37791, None)
[2022-12-30T09:08:06.344+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:06 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.2.15, 37791, None)
[2022-12-30T09:08:06.346+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:06 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.2.15, 37791, None)
[2022-12-30T09:08:08.815+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:08 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2022-12-30T09:08:08.885+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:08 INFO SharedState: Warehouse path is 'file:/home/momo/Bureau/spark-warehouse'.
[2022-12-30T09:08:13.230+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:13 INFO InMemoryFileIndex: It took 64 ms to list leaf files for 1 paths.
[2022-12-30T09:08:13.378+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:13 INFO InMemoryFileIndex: It took 2 ms to list leaf files for 1 paths.
[2022-12-30T09:08:17.980+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:17 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:08:17.982+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:17 INFO FileSourceStrategy: Post-Scan Filters: (length(trim(value#0, None)) > 0)
[2022-12-30T09:08:17.986+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:17 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
[2022-12-30T09:08:19.260+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO CodeGenerator: Code generated in 487.064996 ms
[2022-12-30T09:08:19.340+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.6 KiB, free 434.2 MiB)
[2022-12-30T09:08:19.394+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 434.2 MiB)
[2022-12-30T09:08:19.399+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.2.15:37791 (size: 34.0 KiB, free: 434.4 MiB)
[2022-12-30T09:08:19.403+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO SparkContext: Created broadcast 0 from csv at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:19.413+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:08:19.546+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:19.559+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO DAGScheduler: Got job 0 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:19.560+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO DAGScheduler: Final stage: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:19.560+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:08:19.561+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:19.565+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:19.672+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 11.8 KiB, free 434.2 MiB)
[2022-12-30T09:08:19.674+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.2 MiB)
[2022-12-30T09:08:19.678+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.2.15:37791 (size: 5.9 KiB, free: 434.4 MiB)
[2022-12-30T09:08:19.679+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:19.700+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:19.703+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2022-12-30T09:08:19.783+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:19.811+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2022-12-30T09:08:19.970+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:19 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:08:20.027+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO CodeGenerator: Code generated in 38.077458 ms
[2022-12-30T09:08:20.219+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1792 bytes result sent to driver
[2022-12-30T09:08:20.274+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 507 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:20.285+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2022-12-30T09:08:20.339+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO DAGScheduler: ResultStage 0 (csv at NativeMethodAccessorImpl.java:0) finished in 0,760 s
[2022-12-30T09:08:20.371+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:08:20.379+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2022-12-30T09:08:20.447+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO DAGScheduler: Job 0 finished: csv at NativeMethodAccessorImpl.java:0, took 0,885571 s
[2022-12-30T09:08:20.508+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO CodeGenerator: Code generated in 32.766221 ms
[2022-12-30T09:08:20.673+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:08:20.673+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:08:20.674+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO FileSourceStrategy: Output Data Schema: struct<value: string>
[2022-12-30T09:08:20.688+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 199.6 KiB, free 434.0 MiB)
[2022-12-30T09:08:20.700+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.9 MiB)
[2022-12-30T09:08:20.700+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.2.15:37791 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:20.703+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO SparkContext: Created broadcast 2 from csv at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:20.707+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:08:20.825+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:20.827+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO DAGScheduler: Got job 1 (csv at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:20.828+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO DAGScheduler: Final stage: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:20.828+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:08:20.829+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:20.831+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:20.976+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 25.0 KiB, free 433.9 MiB)
[2022-12-30T09:08:20.978+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 11.8 KiB, free 433.9 MiB)
[2022-12-30T09:08:20.979+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.2.15:37791 (size: 11.8 KiB, free: 434.3 MiB)
[2022-12-30T09:08:20.989+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:21.001+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[9] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:21.001+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2022-12-30T09:08:21.009+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:21.010+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2022-12-30T09:08:21.122+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:08:21.296+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 1780 bytes result sent to driver
[2022-12-30T09:08:21.300+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 292 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:21.301+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2022-12-30T09:08:21.307+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO DAGScheduler: ResultStage 1 (csv at NativeMethodAccessorImpl.java:0) finished in 0,475 s
[2022-12-30T09:08:21.307+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:08:21.307+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2022-12-30T09:08:21.315+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO DAGScheduler: Job 1 finished: csv at NativeMethodAccessorImpl.java:0, took 0,488829 s
[2022-12-30T09:08:21.388+0100] {spark_submit.py:495} INFO - root
[2022-12-30T09:08:21.388+0100] {spark_submit.py:495} INFO - |-- Code du département: string (nullable = true)
[2022-12-30T09:08:21.388+0100] {spark_submit.py:495} INFO - |-- Libellé du département: string (nullable = true)
[2022-12-30T09:08:21.388+0100] {spark_submit.py:495} INFO - |-- Code de la circonscription: integer (nullable = true)
[2022-12-30T09:08:21.389+0100] {spark_submit.py:495} INFO - |-- Libellé de la circonscription: string (nullable = true)
[2022-12-30T09:08:21.389+0100] {spark_submit.py:495} INFO - |-- Etat saisie: string (nullable = true)
[2022-12-30T09:08:21.389+0100] {spark_submit.py:495} INFO - |-- Inscrits: integer (nullable = true)
[2022-12-30T09:08:21.389+0100] {spark_submit.py:495} INFO - |-- Abstentions: integer (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- % Abs/Ins: double (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- Votants: integer (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- % Vot/Ins: double (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- Blancs: integer (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- % Blancs/Ins: double (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- % Blancs/Vot: double (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- Nuls: integer (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- % Nuls/Ins: double (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- % Nuls/Vot: double (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- Exprimés: integer (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- % Exp/Ins: double (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- % Exp/Vot: double (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- N°Panneau: integer (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- Sexe: string (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- Nom: string (nullable = true)
[2022-12-30T09:08:21.390+0100] {spark_submit.py:495} INFO - |-- Prénom: string (nullable = true)
[2022-12-30T09:08:21.391+0100] {spark_submit.py:495} INFO - |-- Voix: integer (nullable = true)
[2022-12-30T09:08:21.391+0100] {spark_submit.py:495} INFO - |-- % Voix/Ins: double (nullable = true)
[2022-12-30T09:08:21.391+0100] {spark_submit.py:495} INFO - |-- % Voix/Exp: double (nullable = true)
[2022-12-30T09:08:21.391+0100] {spark_submit.py:495} INFO - 
[2022-12-30T09:08:21.591+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:08:21.592+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:08:21.594+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T09:08:21.630+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2022-12-30T09:08:21.834+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO CodeGenerator: Code generated in 86.5898 ms
[2022-12-30T09:08:21.839+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 199.4 KiB, free 433.7 MiB)
[2022-12-30T09:08:21.923+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.7 MiB)
[2022-12-30T09:08:21.937+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.2.15:37791 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:21.938+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO SparkContext: Created broadcast 4 from showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:21.943+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:08:21.963+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.2.15:37791 in memory (size: 11.8 KiB, free: 434.3 MiB)
[2022-12-30T09:08:21.970+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:21.976+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:21.976+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:21.976+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:08:21.976+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:21.984+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:21 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:22.010+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 27.1 KiB, free 433.7 MiB)
[2022-12-30T09:08:22.010+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.2.15:37791 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2022-12-30T09:08:22.057+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 9.9 KiB, free 433.7 MiB)
[2022-12-30T09:08:22.062+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.2.15:37791 (size: 9.9 KiB, free: 434.3 MiB)
[2022-12-30T09:08:22.064+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:22.065+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[13] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:22.066+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2022-12-30T09:08:22.069+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4923 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:22.069+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 2)
[2022-12-30T09:08:22.111+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:08:22.122+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.2.15:37791 in memory (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:22.199+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO CodeGenerator: Code generated in 45.751344 ms
[2022-12-30T09:08:22.233+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 2). 4513 bytes result sent to driver
[2022-12-30T09:08:22.234+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 166 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:22.235+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 0,250 s
[2022-12-30T09:08:22.235+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:08:22.237+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2022-12-30T09:08:22.237+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2022-12-30T09:08:22.237+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0,261807 s
[2022-12-30T09:08:22.281+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO CodeGenerator: Code generated in 30.970382 ms
[2022-12-30T09:08:22.291+0100] {spark_submit.py:495} INFO - +-------------------+----------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:08:22.291+0100] {spark_submit.py:495} INFO - |Code du département|Libellé du département|Code de la circonscription|Libellé de la circonscription|Etat saisie|Inscrits|Abstentions|% Abs/Ins|Votants|% Vot/Ins|Blancs|% Blancs/Ins|% Blancs/Vot|Nuls|% Nuls/Ins|% Nuls/Vot|Exprimés|% Exp/Ins|% Exp/Vot|N°Panneau|Sexe|    Nom|  Prénom|Voix|% Voix/Ins|% Voix/Exp|
[2022-12-30T09:08:22.291+0100] {spark_submit.py:495} INFO - +-------------------+----------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:08:22.291+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         1|         1ère circonscription|    Complet|   85723|      18592|    21.69|  67131|    78.31|  1154|        1.35|        1.72| 393|      0.46|      0.59|   65584|    76.51|     97.7|        1|   F|ARTHAUD|Nathalie| 317|      0.37|      0.48|
[2022-12-30T09:08:22.291+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         2|         2ème circonscription|    Complet|   99383|      19917|    20.04|  79466|    79.96|  1367|        1.38|        1.72| 352|      0.35|      0.44|   77747|    78.23|    97.84|        1|   F|ARTHAUD|Nathalie| 354|      0.36|      0.46|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         3|         3ème circonscription|    Complet|   81500|      20440|    25.08|  61060|    74.92|   851|        1.04|        1.39| 290|      0.36|      0.47|   59919|    73.52|    98.13|        1|   F|ARTHAUD|Nathalie| 275|      0.34|      0.46|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         4|         4ème circonscription|    Complet|   94359|      19826|    21.01|  74533|    78.99|  1299|        1.38|        1.74| 474|       0.5|      0.64|   72760|    77.11|    97.62|        1|   F|ARTHAUD|Nathalie| 376|       0.4|      0.52|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 01|                   Ain|                         5|         5ème circonscription|    Complet|   77144|      18766|    24.33|  58378|    75.67|   970|        1.26|        1.66| 394|      0.51|      0.67|   57014|    73.91|    97.66|        1|   F|ARTHAUD|Nathalie| 336|      0.44|      0.59|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         1|         1ère circonscription|    Complet|   72206|      18597|    25.76|  53609|    74.24|   740|        1.02|        1.38| 404|      0.56|      0.75|   52465|    72.66|    97.87|        1|   F|ARTHAUD|Nathalie| 410|      0.57|      0.78|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         2|         2ème circonscription|    Complet|   73111|      20530|    28.08|  52581|    71.92|   772|        1.06|        1.47| 403|      0.55|      0.77|   51406|    70.31|    97.77|        1|   F|ARTHAUD|Nathalie| 372|      0.51|      0.72|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         3|         3ème circonscription|    Complet|   66580|      17358|    26.07|  49222|    73.93|   699|        1.05|        1.42| 398|       0.6|      0.81|   48125|    72.28|    97.77|        1|   F|ARTHAUD|Nathalie| 358|      0.54|      0.74|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         4|         4ème circonscription|    Complet|   78699|      22961|    29.18|  55738|    70.82|   681|        0.87|        1.22|1143|      1.45|      2.05|   53914|    68.51|    96.73|        1|   F|ARTHAUD|Nathalie| 391|       0.5|      0.73|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 02|                 Aisne|                         5|         5ème circonscription|    Complet|   82948|      21643|    26.09|  61305|    73.91|   875|        1.05|        1.43| 480|      0.58|      0.78|   59950|    72.27|    97.79|        1|   F|ARTHAUD|Nathalie| 507|      0.61|      0.85|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 03|                Allier|                         1|         1ère circonscription|    Complet|   89193|      20597|    23.09|  68596|    76.91|  1330|        1.49|        1.94| 599|      0.67|      0.87|   66667|    74.74|    97.19|        1|   F|ARTHAUD|Nathalie| 528|      0.59|      0.79|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 03|                Allier|                         2|         2ème circonscription|    Complet|   80780|      19459|    24.09|  61321|    75.91|  1207|        1.49|        1.97| 649|       0.8|      1.06|   59465|    73.61|    96.97|        1|   F|ARTHAUD|Nathalie| 446|      0.55|      0.75|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 03|                Allier|                         3|         3ème circonscription|    Complet|   80018|      18441|    23.05|  61577|    76.95|  1212|        1.51|        1.97| 542|      0.68|      0.88|   59823|    74.76|    97.15|        1|   F|ARTHAUD|Nathalie| 385|      0.48|      0.64|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 04|  Alpes-de-Haute-Pr...|                         1|         1ère circonscription|    Complet|   61692|      13750|    22.29|  47942|    77.71|   691|        1.12|        1.44| 315|      0.51|      0.66|   46936|    76.08|     97.9|        1|   F|ARTHAUD|Nathalie| 275|      0.45|      0.59|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 04|  Alpes-de-Haute-Pr...|                         2|         2ème circonscription|    Complet|   66383|      15540|    23.41|  50843|    76.59|   787|        1.19|        1.55| 309|      0.47|      0.61|   49747|    74.94|    97.84|        1|   F|ARTHAUD|Nathalie| 230|      0.35|      0.46|
[2022-12-30T09:08:22.292+0100] {spark_submit.py:495} INFO - |                 05|          Hautes-Alpes|                         1|         1ère circonscription|    Complet|   59486|      13601|    22.86|  45885|    77.14|   731|        1.23|        1.59| 287|      0.48|      0.63|   44867|    75.42|    97.78|        1|   F|ARTHAUD|Nathalie| 234|      0.39|      0.52|
[2022-12-30T09:08:22.293+0100] {spark_submit.py:495} INFO - |                 05|          Hautes-Alpes|                         2|         2ème circonscription|    Complet|   54033|      11756|    21.76|  42277|    78.24|   664|        1.23|        1.57| 245|      0.45|      0.58|   41368|    76.56|    97.85|        1|   F|ARTHAUD|Nathalie| 194|      0.36|      0.47|
[2022-12-30T09:08:22.293+0100] {spark_submit.py:495} INFO - |                 06|       Alpes-Maritimes|                         1|         1ère circonscription|    Complet|   81800|      24731|    30.23|  57069|    69.77|   603|        0.74|        1.06| 354|      0.43|      0.62|   56112|     68.6|    98.32|        1|   F|ARTHAUD|Nathalie| 166|       0.2|       0.3|
[2022-12-30T09:08:22.293+0100] {spark_submit.py:495} INFO - |                 06|       Alpes-Maritimes|                         2|         2ème circonscription|    Complet|   88918|      22495|     25.3|  66423|     74.7|   949|        1.07|        1.43| 341|      0.38|      0.51|   65133|    73.25|    98.06|        1|   F|ARTHAUD|Nathalie| 216|      0.24|      0.33|
[2022-12-30T09:08:22.293+0100] {spark_submit.py:495} INFO - |                 06|       Alpes-Maritimes|                         3|         3ème circonscription|    Complet|   90956|      26607|    29.25|  64349|    70.75|   789|        0.87|        1.23| 342|      0.38|      0.53|   63218|     69.5|    98.24|        1|   F|ARTHAUD|Nathalie| 206|      0.23|      0.33|
[2022-12-30T09:08:22.293+0100] {spark_submit.py:495} INFO - +-------------------+----------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:08:22.293+0100] {spark_submit.py:495} INFO - only showing top 20 rows
[2022-12-30T09:08:22.293+0100] {spark_submit.py:495} INFO - 
[2022-12-30T09:08:22.372+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:08:22.372+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:08:22.373+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T09:08:22.484+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:08:22.630+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO CodeGenerator: Code generated in 108.917557 ms
[2022-12-30T09:08:22.634+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 199.4 KiB, free 433.7 MiB)
[2022-12-30T09:08:22.685+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.7 MiB)
[2022-12-30T09:08:22.686+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.2.15:37791 in memory (size: 9.9 KiB, free: 434.3 MiB)
[2022-12-30T09:08:22.687+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.2.15:37791 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:22.688+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO SparkContext: Created broadcast 6 from count at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:22.693+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:08:22.730+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.2.15:37791 in memory (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:22.782+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.2.15:37791 in memory (size: 34.0 KiB, free: 434.4 MiB)
[2022-12-30T09:08:22.792+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO DAGScheduler: Registering RDD 17 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2022-12-30T09:08:22.796+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:22.796+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO DAGScheduler: Final stage: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:22.798+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:08:22.800+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:22.813+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:22.871+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 57.4 KiB, free 434.1 MiB)
[2022-12-30T09:08:22.879+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 434.1 MiB)
[2022-12-30T09:08:22.894+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.2.15:37791 (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:22.900+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:22.905+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[17] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:22.906+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2022-12-30T09:08:22.910+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:22.911+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO Executor: Running task 0.0 in stage 3.0 (TID 3)
[2022-12-30T09:08:22.976+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO CodeGenerator: Code generated in 20.729688 ms
[2022-12-30T09:08:22.991+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:22 INFO CodeGenerator: Code generated in 5.20984 ms
[2022-12-30T09:08:23.013+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO CodeGenerator: Code generated in 12.489278 ms
[2022-12-30T09:08:23.026+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:08:23.396+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 3). 2810 bytes result sent to driver
[2022-12-30T09:08:23.428+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 518 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:23.431+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2022-12-30T09:08:23.435+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO DAGScheduler: ShuffleMapStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0,613 s
[2022-12-30T09:08:23.435+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:08:23.435+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO DAGScheduler: running: Set()
[2022-12-30T09:08:23.435+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:08:23.435+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO DAGScheduler: failed: Set()
[2022-12-30T09:08:23.499+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO ShufflePartitionsUtil: For shuffle(0), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T09:08:23.575+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:08:23.736+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO CodeGenerator: Code generated in 78.661849 ms
[2022-12-30T09:08:23.988+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO DAGScheduler: Registering RDD 20 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2022-12-30T09:08:23.989+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO DAGScheduler: Got map stage job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:23.990+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO DAGScheduler: Final stage: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:23.990+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 4)
[2022-12-30T09:08:23.990+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:23 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:24.006+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO DAGScheduler: Submitting ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:24.173+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 62.1 KiB, free 434.0 MiB)
[2022-12-30T09:08:24.249+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 434.0 MiB)
[2022-12-30T09:08:24.254+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.2.15:37791 (size: 23.7 KiB, free: 434.3 MiB)
[2022-12-30T09:08:24.254+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:24.259+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 5 (MapPartitionsRDD[20] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:24.260+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks resource profile 0
[2022-12-30T09:08:24.288+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 4) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:24.290+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO Executor: Running task 0.0 in stage 5.0 (TID 4)
[2022-12-30T09:08:24.356+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.2.15:37791 in memory (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:24.667+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:08:24.693+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 101 ms
[2022-12-30T09:08:24.888+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO Executor: Finished task 0.0 in stage 5.0 (TID 4). 4309 bytes result sent to driver
[2022-12-30T09:08:24.910+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 4) in 637 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:24.911+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2022-12-30T09:08:24.915+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO DAGScheduler: ShuffleMapStage 5 (count at NativeMethodAccessorImpl.java:0) finished in 0,809 s
[2022-12-30T09:08:24.915+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:08:24.915+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO DAGScheduler: running: Set()
[2022-12-30T09:08:24.915+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:08:24.916+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO DAGScheduler: failed: Set()
[2022-12-30T09:08:24.994+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:24 INFO CodeGenerator: Code generated in 20.500537 ms
[2022-12-30T09:08:25.040+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:25.050+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Got job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:25.051+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Final stage: ResultStage 8 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:25.051+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 7)
[2022-12-30T09:08:25.051+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:25.073+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:25.078+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 11.1 KiB, free 434.1 MiB)
[2022-12-30T09:08:25.115+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.1 MiB)
[2022-12-30T09:08:25.116+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.2.15:37791 (size: 5.5 KiB, free: 434.3 MiB)
[2022-12-30T09:08:25.121+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:25.122+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 8 (MapPartitionsRDD[23] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:25.122+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO TaskSchedulerImpl: Adding task set 8.0 with 1 tasks resource profile 0
[2022-12-30T09:08:25.122+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 5) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:25.122+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO Executor: Running task 0.0 in stage 8.0 (TID 5)
[2022-12-30T09:08:25.132+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:08:25.133+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2022-12-30T09:08:25.138+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.2.15:37791 in memory (size: 23.7 KiB, free: 434.4 MiB)
[2022-12-30T09:08:25.209+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO Executor: Finished task 0.0 in stage 8.0 (TID 5). 2699 bytes result sent to driver
[2022-12-30T09:08:25.215+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 5) in 90 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:25.215+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool
[2022-12-30T09:08:25.216+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: ResultStage 8 (count at NativeMethodAccessorImpl.java:0) finished in 0,142 s
[2022-12-30T09:08:25.216+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:08:25.216+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO TaskSchedulerImpl: Killing all running tasks in stage 8: Stage finished
[2022-12-30T09:08:25.216+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Job 5 finished: count at NativeMethodAccessorImpl.java:0, took 0,171984 s
[2022-12-30T09:08:25.233+0100] {spark_submit.py:495} INFO - ************Distinct count**************** :577
[2022-12-30T09:08:25.432+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:08:25.433+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:08:25.433+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T09:08:25.493+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:08:25.535+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 199.4 KiB, free 434.0 MiB)
[2022-12-30T09:08:25.567+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.9 MiB)
[2022-12-30T09:08:25.568+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.2.15:37791 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:25.571+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO SparkContext: Created broadcast 10 from showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:25.573+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:08:25.611+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Registering RDD 27 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2022-12-30T09:08:25.612+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Got map stage job 6 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:25.612+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Final stage: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:25.612+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:08:25.613+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:25.615+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.2.15:37791 in memory (size: 34.0 KiB, free: 434.4 MiB)
[2022-12-30T09:08:25.618+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Submitting ShuffleMapStage 9 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:25.628+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 57.4 KiB, free 434.1 MiB)
[2022-12-30T09:08:25.630+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 434.1 MiB)
[2022-12-30T09:08:25.634+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.2.15:37791 (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:25.635+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:25.636+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 9 (MapPartitionsRDD[27] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:25.636+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2022-12-30T09:08:25.638+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:25.643+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO Executor: Running task 0.0 in stage 9.0 (TID 6)
[2022-12-30T09:08:25.688+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:08:25.696+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.2.15:37791 in memory (size: 5.5 KiB, free: 434.3 MiB)
[2022-12-30T09:08:25.883+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO Executor: Finished task 0.0 in stage 9.0 (TID 6). 2767 bytes result sent to driver
[2022-12-30T09:08:25.884+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 247 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:25.884+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2022-12-30T09:08:25.885+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: ShuffleMapStage 9 (showString at NativeMethodAccessorImpl.java:0) finished in 0,269 s
[2022-12-30T09:08:25.885+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:08:25.886+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: running: Set()
[2022-12-30T09:08:25.886+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:08:25.886+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO DAGScheduler: failed: Set()
[2022-12-30T09:08:25.889+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO ShufflePartitionsUtil: For shuffle(2), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T09:08:25.905+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:08:25.988+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:25 INFO CodeGenerator: Code generated in 54.373888 ms
[2022-12-30T09:08:26.040+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:26.041+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Got job 7 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:26.041+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Final stage: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:26.041+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 10)
[2022-12-30T09:08:26.041+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:26.042+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Submitting ResultStage 11 (MapPartitionsRDD[30] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:26.063+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 73.4 KiB, free 434.0 MiB)
[2022-12-30T09:08:26.064+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 25.7 KiB, free 434.0 MiB)
[2022-12-30T09:08:26.082+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.2.15:37791 (size: 25.7 KiB, free: 434.3 MiB)
[2022-12-30T09:08:26.084+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:26.085+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 11 (MapPartitionsRDD[30] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:26.085+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSchedulerImpl: Adding task set 11.0 with 1 tasks resource profile 0
[2022-12-30T09:08:26.086+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 7) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:26.087+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO Executor: Running task 0.0 in stage 11.0 (TID 7)
[2022-12-30T09:08:26.104+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:08:26.104+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2022-12-30T09:08:26.115+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.2.15:37791 in memory (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:26.146+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO Executor: Finished task 0.0 in stage 11.0 (TID 7). 7622 bytes result sent to driver
[2022-12-30T09:08:26.147+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 7) in 62 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:26.148+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool
[2022-12-30T09:08:26.150+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: ResultStage 11 (showString at NativeMethodAccessorImpl.java:0) finished in 0,095 s
[2022-12-30T09:08:26.150+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Job 7 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:08:26.150+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 11: Stage finished
[2022-12-30T09:08:26.150+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Job 7 finished: showString at NativeMethodAccessorImpl.java:0, took 0,108832 s
[2022-12-30T09:08:26.168+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |Code du département|Libellé du département         |Code de la circonscription|Libellé de la circonscription|Etat saisie|Inscrits|Abstentions|% Abs/Ins|Votants|% Vot/Ins|Blancs|% Blancs/Ins|% Blancs/Vot|Nuls|% Nuls/Ins|% Nuls/Vot|Exprimés|% Exp/Ins|% Exp/Vot|N°Panneau|Sexe|Nom    |Prénom  |Voix|% Voix/Ins|% Voix/Exp|
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |06                 |Alpes-Maritimes                |5                         |5ème circonscription         |Complet    |90651   |24266      |26.77    |66385  |73.23    |847   |0.93        |1.28        |843 |0.93      |1.27      |64695   |71.37    |97.45    |1        |F   |ARTHAUD|Nathalie|196 |0.22      |0.3       |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |ZZ                 |Français établis hors de France|10                        |10ème circonscription        |Complet    |103910  |63575      |61.18    |40335  |38.82    |365   |0.35        |0.9         |191 |0.18      |0.47      |39779   |38.28    |98.62    |1        |F   |ARTHAUD|Nathalie|90  |0.09      |0.23      |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |24                 |Dordogne                       |2                         |2ème circonscription         |Complet    |84067   |18394      |21.88    |65673  |78.12    |832   |0.99        |1.27        |580 |0.69      |0.88      |64261   |76.44    |97.85    |1        |F   |ARTHAUD|Nathalie|314 |0.37      |0.49      |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |2                         |2ème circonscription         |Complet    |85933   |16008      |18.63    |69925  |81.37    |877   |1.02        |1.25        |287 |0.33      |0.41      |68761   |80.02    |98.34    |1        |F   |ARTHAUD|Nathalie|220 |0.26      |0.32      |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |ZB                 |Martinique                     |1                         |1ère circonscription         |Complet    |80037   |44808      |55.98    |35229  |44.02    |1154  |1.44        |3.28        |823 |1.03      |2.34      |33252   |41.55    |94.39    |1        |F   |ARTHAUD|Nathalie|432 |0.54      |1.3       |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |ZC                 |Guyane                         |1                         |1ère circonscription         |Complet    |56628   |32823      |57.96    |23805  |42.04    |556   |0.98        |2.34        |377 |0.67      |1.58      |22872   |40.39    |96.08    |1        |F   |ARTHAUD|Nathalie|176 |0.31      |0.77      |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |01                 |Ain                            |1                         |1ère circonscription         |Complet    |85723   |18592      |21.69    |67131  |78.31    |1154  |1.35        |1.72        |393 |0.46      |0.59      |65584   |76.51    |97.7     |1        |F   |ARTHAUD|Nathalie|317 |0.37      |0.48      |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |61                 |Orne                           |2                         |2ème circonscription         |Complet    |66030   |16122      |24.42    |49908  |75.58    |817   |1.24        |1.64        |278 |0.42      |0.56      |48813   |73.93    |97.81    |1        |F   |ARTHAUD|Nathalie|330 |0.5       |0.68      |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |11                        |11ème circonscription        |Complet    |68878   |16249      |23.59    |52629  |76.41    |692   |1.0         |1.31        |318 |0.46      |0.6       |51619   |74.94    |98.08    |1        |F   |ARTHAUD|Nathalie|227 |0.33      |0.44      |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |12                        |12ème circonscription        |Complet    |70828   |15015      |21.2     |55813  |78.8     |815   |1.15        |1.46        |233 |0.33      |0.42      |54765   |77.32    |98.12    |1        |F   |ARTHAUD|Nathalie|222 |0.31      |0.41      |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |50                 |Manche                         |2                         |2ème circonscription         |Complet    |96973   |22676      |23.38    |74297  |76.62    |1262  |1.3         |1.7         |607 |0.63      |0.82      |72428   |74.69    |97.48    |1        |F   |ARTHAUD|Nathalie|524 |0.54      |0.72      |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |9                         |9ème circonscription         |Complet    |92669   |21481      |23.18    |71188  |76.82    |1021  |1.1         |1.43        |361 |0.39      |0.51      |69806   |75.33    |98.06    |1        |F   |ARTHAUD|Nathalie|366 |0.39      |0.52      |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |92                 |Hauts-de-Seine                 |2                         |2ème circonscription         |Complet    |69068   |13416      |19.42    |55652  |80.58    |795   |1.15        |1.43        |216 |0.31      |0.39      |54641   |79.11    |98.18    |1        |F   |ARTHAUD|Nathalie|169 |0.24      |0.31      |
[2022-12-30T09:08:26.169+0100] {spark_submit.py:495} INFO - |60                 |Oise                           |2                         |2ème circonscription         |Complet    |88749   |21439      |24.16    |67310  |75.84    |1016  |1.14        |1.51        |1150|1.3       |1.71      |65144   |73.4     |96.78    |1        |F   |ARTHAUD|Nathalie|475 |0.54      |0.73      |
[2022-12-30T09:08:26.170+0100] {spark_submit.py:495} INFO - |13                 |Bouches-du-Rhône               |10                        |10ème circonscription        |Complet    |108586  |24129      |22.22    |84457  |77.78    |1235  |1.14        |1.46        |448 |0.41      |0.53      |82774   |76.23    |98.01    |1        |F   |ARTHAUD|Nathalie|269 |0.25      |0.32      |
[2022-12-30T09:08:26.170+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |1                         |1ère circonscription         |Complet    |97799   |19432      |19.87    |78367  |80.13    |898   |0.92        |1.15        |416 |0.43      |0.53      |77053   |78.79    |98.32    |1        |F   |ARTHAUD|Nathalie|183 |0.19      |0.24      |
[2022-12-30T09:08:26.170+0100] {spark_submit.py:495} INFO - |91                 |Essonne                        |9                         |9ème circonscription         |Complet    |78393   |18934      |24.15    |59459  |75.85    |870   |1.11        |1.46        |335 |0.43      |0.56      |58254   |74.31    |97.97    |1        |F   |ARTHAUD|Nathalie|265 |0.34      |0.45      |
[2022-12-30T09:08:26.170+0100] {spark_submit.py:495} INFO - |14                 |Calvados                       |6                         |6ème circonscription         |Complet    |95726   |21470      |22.43    |74256  |77.57    |1179  |1.23        |1.59        |589 |0.62      |0.79      |72488   |75.72    |97.62    |1        |F   |ARTHAUD|Nathalie|581 |0.61      |0.8       |
[2022-12-30T09:08:26.170+0100] {spark_submit.py:495} INFO - |22                 |Côtes-d'Armor                  |3                         |3ème circonscription         |Complet    |88709   |17554      |19.79    |71155  |80.21    |1189  |1.34        |1.67        |645 |0.73      |0.91      |69321   |78.14    |97.42    |1        |F   |ARTHAUD|Nathalie|521 |0.59      |0.75      |
[2022-12-30T09:08:26.170+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |10                        |10ème circonscription        |Complet    |69820   |15846      |22.7     |53974  |77.3     |641   |0.92        |1.19        |233 |0.33      |0.43      |53100   |76.05    |98.38    |1        |F   |ARTHAUD|Nathalie|206 |0.3       |0.39      |
[2022-12-30T09:08:26.170+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:08:26.170+0100] {spark_submit.py:495} INFO - only showing top 20 rows
[2022-12-30T09:08:26.170+0100] {spark_submit.py:495} INFO - 
[2022-12-30T09:08:26.204+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.2.15:37791 in memory (size: 25.7 KiB, free: 434.4 MiB)
[2022-12-30T09:08:26.209+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:08:26.210+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:08:26.210+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T09:08:26.268+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:08:26.285+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 199.4 KiB, free 434.0 MiB)
[2022-12-30T09:08:26.314+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.9 MiB)
[2022-12-30T09:08:26.315+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.2.15:37791 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:26.316+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO SparkContext: Created broadcast 13 from count at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:26.321+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:08:26.335+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Registering RDD 34 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2022-12-30T09:08:26.340+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Got map stage job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:26.341+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Final stage: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:26.341+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:08:26.341+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:26.349+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Submitting ShuffleMapStage 12 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:26.364+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 57.4 KiB, free 433.9 MiB)
[2022-12-30T09:08:26.366+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 433.9 MiB)
[2022-12-30T09:08:26.368+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.2.15:37791 (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:26.374+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:26.375+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 12 (MapPartitionsRDD[34] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:26.378+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2022-12-30T09:08:26.380+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 8) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:26.380+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO Executor: Running task 0.0 in stage 12.0 (TID 8)
[2022-12-30T09:08:26.452+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:08:26.600+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO Executor: Finished task 0.0 in stage 12.0 (TID 8). 2767 bytes result sent to driver
[2022-12-30T09:08:26.602+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 8) in 222 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:26.602+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2022-12-30T09:08:26.610+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: ShuffleMapStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0,248 s
[2022-12-30T09:08:26.611+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:08:26.611+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: running: Set()
[2022-12-30T09:08:26.611+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:08:26.611+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: failed: Set()
[2022-12-30T09:08:26.627+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO ShufflePartitionsUtil: For shuffle(3), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T09:08:26.649+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:08:26.693+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Registering RDD 37 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2022-12-30T09:08:26.693+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Got map stage job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:26.693+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Final stage: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:26.693+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
[2022-12-30T09:08:26.694+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:26.698+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Submitting ShuffleMapStage 14 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:26.718+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 62.1 KiB, free 433.8 MiB)
[2022-12-30T09:08:26.722+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 23.7 KiB, free 433.8 MiB)
[2022-12-30T09:08:26.727+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.2.15:37791 (size: 23.7 KiB, free: 434.3 MiB)
[2022-12-30T09:08:26.727+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:26.728+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 14 (MapPartitionsRDD[37] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:26.728+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks resource profile 0
[2022-12-30T09:08:26.731+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 9) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4442 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:26.731+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO Executor: Running task 0.0 in stage 14.0 (TID 9)
[2022-12-30T09:08:26.751+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:08:26.751+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 3 ms
[2022-12-30T09:08:26.801+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.2.15:37791 in memory (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:26.833+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO Executor: Finished task 0.0 in stage 14.0 (TID 9). 4309 bytes result sent to driver
[2022-12-30T09:08:26.834+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 9) in 105 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:26.835+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool
[2022-12-30T09:08:26.838+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: ShuffleMapStage 14 (count at NativeMethodAccessorImpl.java:0) finished in 0,120 s
[2022-12-30T09:08:26.838+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:08:26.838+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: running: Set()
[2022-12-30T09:08:26.838+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:08:26.838+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: failed: Set()
[2022-12-30T09:08:26.844+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.2.15:37791 in memory (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:26.869+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:26.877+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:26.878+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Final stage: ResultStage 17 (count at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:26.878+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
[2022-12-30T09:08:26.878+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:26.880+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:26.881+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 11.1 KiB, free 434.1 MiB)
[2022-12-30T09:08:26.882+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 5.5 KiB, free 434.1 MiB)
[2022-12-30T09:08:26.882+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.2.15:37791 (size: 5.5 KiB, free: 434.3 MiB)
[2022-12-30T09:08:26.882+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:26.884+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:26.884+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks resource profile 0
[2022-12-30T09:08:26.884+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 10) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:26.887+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO Executor: Running task 0.0 in stage 17.0 (TID 10)
[2022-12-30T09:08:26.890+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:08:26.890+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2022-12-30T09:08:26.890+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO Executor: Finished task 0.0 in stage 17.0 (TID 10). 2656 bytes result sent to driver
[2022-12-30T09:08:26.891+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 10) in 7 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:26.891+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool
[2022-12-30T09:08:26.893+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: ResultStage 17 (count at NativeMethodAccessorImpl.java:0) finished in 0,012 s
[2022-12-30T09:08:26.893+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:08:26.893+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO TaskSchedulerImpl: Killing all running tasks in stage 17: Stage finished
[2022-12-30T09:08:26.893+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0,015867 s
[2022-12-30T09:08:26.897+0100] {spark_submit.py:495} INFO - ****************Distinct count drop******************* :577
[2022-12-30T09:08:26.932+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.2.15:37791 in memory (size: 23.7 KiB, free: 434.4 MiB)
[2022-12-30T09:08:26.952+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO FileSourceStrategy: Pushed Filters:
[2022-12-30T09:08:26.953+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO FileSourceStrategy: Post-Scan Filters:
[2022-12-30T09:08:26.953+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO FileSourceStrategy: Output Data Schema: struct<Code du département: string, Libellé du département: string, Code de la circonscription: int, Libellé de la circonscription: string, Etat saisie: string ... 24 more fields>
[2022-12-30T09:08:26.979+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:08:26.996+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:26 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 10.0.2.15:37791 in memory (size: 5.5 KiB, free: 434.4 MiB)
[2022-12-30T09:08:27.026+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 199.4 KiB, free 434.0 MiB)
[2022-12-30T09:08:27.036+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 34.0 KiB, free 433.9 MiB)
[2022-12-30T09:08:27.037+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.2.15:37791 (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:27.039+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO SparkContext: Created broadcast 17 from showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:27.040+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4285594 bytes, open cost is considered as scanning 4194304 bytes.
[2022-12-30T09:08:27.050+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Registering RDD 44 (showString at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2022-12-30T09:08:27.050+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Got map stage job 11 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:27.050+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Final stage: ShuffleMapStage 18 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:27.050+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Parents of final stage: List()
[2022-12-30T09:08:27.050+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:27.051+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[44] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:27.056+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 57.4 KiB, free 433.9 MiB)
[2022-12-30T09:08:27.058+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 22.0 KiB, free 433.9 MiB)
[2022-12-30T09:08:27.058+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.2.15:37791 (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:27.059+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:27.060+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[44] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:27.060+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2022-12-30T09:08:27.061+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 11) (10.0.2.15, executor driver, partition 0, PROCESS_LOCAL, 4912 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:27.065+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO Executor: Running task 0.0 in stage 18.0 (TID 11)
[2022-12-30T09:08:27.094+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO FileScanRDD: Reading File path: file:///home/momo/Bureau/nifi_transformer/datav1.csv, range: 0-91290, partition values: [empty row]
[2022-12-30T09:08:27.158+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO Executor: Finished task 0.0 in stage 18.0 (TID 11). 2724 bytes result sent to driver
[2022-12-30T09:08:27.161+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 11) in 99 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:27.161+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2022-12-30T09:08:27.161+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: ShuffleMapStage 18 (showString at NativeMethodAccessorImpl.java:0) finished in 0,109 s
[2022-12-30T09:08:27.162+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: looking for newly runnable stages
[2022-12-30T09:08:27.162+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: running: Set()
[2022-12-30T09:08:27.162+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: waiting: Set()
[2022-12-30T09:08:27.162+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: failed: Set()
[2022-12-30T09:08:27.171+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO ShufflePartitionsUtil: For shuffle(5), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2022-12-30T09:08:27.174+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO HashAggregateExec: spark.sql.codegen.aggregate.map.twolevel.enabled is set to true, but current version of codegened fast hashmap does not support this aggregate.
[2022-12-30T09:08:27.206+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 10.0.2.15:37791 in memory (size: 22.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:27.222+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2022-12-30T09:08:27.224+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Got job 12 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2022-12-30T09:08:27.224+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Final stage: ResultStage 20 (showString at NativeMethodAccessorImpl.java:0)
[2022-12-30T09:08:27.224+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 19)
[2022-12-30T09:08:27.225+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Missing parents: List()
[2022-12-30T09:08:27.234+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2022-12-30T09:08:27.264+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 73.4 KiB, free 433.9 MiB)
[2022-12-30T09:08:27.265+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 25.6 KiB, free 433.8 MiB)
[2022-12-30T09:08:27.266+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.2.15:37791 (size: 25.6 KiB, free: 434.3 MiB)
[2022-12-30T09:08:27.267+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1513
[2022-12-30T09:08:27.267+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[47] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2022-12-30T09:08:27.270+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks resource profile 0
[2022-12-30T09:08:27.272+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 12) (10.0.2.15, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
[2022-12-30T09:08:27.272+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO Executor: Running task 0.0 in stage 20.0 (TID 12)
[2022-12-30T09:08:27.282+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO ShuffleBlockFetcherIterator: Getting 1 (120.8 KiB) non-empty blocks including 1 (120.8 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2022-12-30T09:08:27.286+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 4 ms
[2022-12-30T09:08:27.304+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO Executor: Finished task 0.0 in stage 20.0 (TID 12). 7622 bytes result sent to driver
[2022-12-30T09:08:27.311+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 12) in 34 ms on 10.0.2.15 (executor driver) (1/1)
[2022-12-30T09:08:27.311+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool
[2022-12-30T09:08:27.311+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: ResultStage 20 (showString at NativeMethodAccessorImpl.java:0) finished in 0,069 s
[2022-12-30T09:08:27.311+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2022-12-30T09:08:27.311+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO TaskSchedulerImpl: Killing all running tasks in stage 20: Stage finished
[2022-12-30T09:08:27.311+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO DAGScheduler: Job 12 finished: showString at NativeMethodAccessorImpl.java:0, took 0,084407 s
[2022-12-30T09:08:27.324+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |Code du département|Libellé du département         |Code de la circonscription|Libellé de la circonscription|Etat saisie|Inscrits|Abstentions|% Abs/Ins|Votants|% Vot/Ins|Blancs|% Blancs/Ins|% Blancs/Vot|Nuls|% Nuls/Ins|% Nuls/Vot|Exprimés|% Exp/Ins|% Exp/Vot|N°Panneau|Sexe|Nom    |Prénom  |Voix|% Voix/Ins|% Voix/Exp|
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |06                 |Alpes-Maritimes                |5                         |5ème circonscription         |Complet    |90651   |24266      |26.77    |66385  |73.23    |847   |0.93        |1.28        |843 |0.93      |1.27      |64695   |71.37    |97.45    |1        |F   |ARTHAUD|Nathalie|196 |0.22      |0.3       |
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |ZZ                 |Français établis hors de France|10                        |10ème circonscription        |Complet    |103910  |63575      |61.18    |40335  |38.82    |365   |0.35        |0.9         |191 |0.18      |0.47      |39779   |38.28    |98.62    |1        |F   |ARTHAUD|Nathalie|90  |0.09      |0.23      |
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |24                 |Dordogne                       |2                         |2ème circonscription         |Complet    |84067   |18394      |21.88    |65673  |78.12    |832   |0.99        |1.27        |580 |0.69      |0.88      |64261   |76.44    |97.85    |1        |F   |ARTHAUD|Nathalie|314 |0.37      |0.49      |
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |2                         |2ème circonscription         |Complet    |85933   |16008      |18.63    |69925  |81.37    |877   |1.02        |1.25        |287 |0.33      |0.41      |68761   |80.02    |98.34    |1        |F   |ARTHAUD|Nathalie|220 |0.26      |0.32      |
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |ZB                 |Martinique                     |1                         |1ère circonscription         |Complet    |80037   |44808      |55.98    |35229  |44.02    |1154  |1.44        |3.28        |823 |1.03      |2.34      |33252   |41.55    |94.39    |1        |F   |ARTHAUD|Nathalie|432 |0.54      |1.3       |
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |ZC                 |Guyane                         |1                         |1ère circonscription         |Complet    |56628   |32823      |57.96    |23805  |42.04    |556   |0.98        |2.34        |377 |0.67      |1.58      |22872   |40.39    |96.08    |1        |F   |ARTHAUD|Nathalie|176 |0.31      |0.77      |
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |01                 |Ain                            |1                         |1ère circonscription         |Complet    |85723   |18592      |21.69    |67131  |78.31    |1154  |1.35        |1.72        |393 |0.46      |0.59      |65584   |76.51    |97.7     |1        |F   |ARTHAUD|Nathalie|317 |0.37      |0.48      |
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |61                 |Orne                           |2                         |2ème circonscription         |Complet    |66030   |16122      |24.42    |49908  |75.58    |817   |1.24        |1.64        |278 |0.42      |0.56      |48813   |73.93    |97.81    |1        |F   |ARTHAUD|Nathalie|330 |0.5       |0.68      |
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |11                        |11ème circonscription        |Complet    |68878   |16249      |23.59    |52629  |76.41    |692   |1.0         |1.31        |318 |0.46      |0.6       |51619   |74.94    |98.08    |1        |F   |ARTHAUD|Nathalie|227 |0.33      |0.44      |
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |12                        |12ème circonscription        |Complet    |70828   |15015      |21.2     |55813  |78.8     |815   |1.15        |1.46        |233 |0.33      |0.42      |54765   |77.32    |98.12    |1        |F   |ARTHAUD|Nathalie|222 |0.31      |0.41      |
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |50                 |Manche                         |2                         |2ème circonscription         |Complet    |96973   |22676      |23.38    |74297  |76.62    |1262  |1.3         |1.7         |607 |0.63      |0.82      |72428   |74.69    |97.48    |1        |F   |ARTHAUD|Nathalie|524 |0.54      |0.72      |
[2022-12-30T09:08:27.325+0100] {spark_submit.py:495} INFO - |78                 |Yvelines                       |9                         |9ème circonscription         |Complet    |92669   |21481      |23.18    |71188  |76.82    |1021  |1.1         |1.43        |361 |0.39      |0.51      |69806   |75.33    |98.06    |1        |F   |ARTHAUD|Nathalie|366 |0.39      |0.52      |
[2022-12-30T09:08:27.326+0100] {spark_submit.py:495} INFO - |92                 |Hauts-de-Seine                 |2                         |2ème circonscription         |Complet    |69068   |13416      |19.42    |55652  |80.58    |795   |1.15        |1.43        |216 |0.31      |0.39      |54641   |79.11    |98.18    |1        |F   |ARTHAUD|Nathalie|169 |0.24      |0.31      |
[2022-12-30T09:08:27.326+0100] {spark_submit.py:495} INFO - |60                 |Oise                           |2                         |2ème circonscription         |Complet    |88749   |21439      |24.16    |67310  |75.84    |1016  |1.14        |1.51        |1150|1.3       |1.71      |65144   |73.4     |96.78    |1        |F   |ARTHAUD|Nathalie|475 |0.54      |0.73      |
[2022-12-30T09:08:27.326+0100] {spark_submit.py:495} INFO - |13                 |Bouches-du-Rhône               |10                        |10ème circonscription        |Complet    |108586  |24129      |22.22    |84457  |77.78    |1235  |1.14        |1.46        |448 |0.41      |0.53      |82774   |76.23    |98.01    |1        |F   |ARTHAUD|Nathalie|269 |0.25      |0.32      |
[2022-12-30T09:08:27.326+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |1                         |1ère circonscription         |Complet    |97799   |19432      |19.87    |78367  |80.13    |898   |0.92        |1.15        |416 |0.43      |0.53      |77053   |78.79    |98.32    |1        |F   |ARTHAUD|Nathalie|183 |0.19      |0.24      |
[2022-12-30T09:08:27.326+0100] {spark_submit.py:495} INFO - |91                 |Essonne                        |9                         |9ème circonscription         |Complet    |78393   |18934      |24.15    |59459  |75.85    |870   |1.11        |1.46        |335 |0.43      |0.56      |58254   |74.31    |97.97    |1        |F   |ARTHAUD|Nathalie|265 |0.34      |0.45      |
[2022-12-30T09:08:27.326+0100] {spark_submit.py:495} INFO - |14                 |Calvados                       |6                         |6ème circonscription         |Complet    |95726   |21470      |22.43    |74256  |77.57    |1179  |1.23        |1.59        |589 |0.62      |0.79      |72488   |75.72    |97.62    |1        |F   |ARTHAUD|Nathalie|581 |0.61      |0.8       |
[2022-12-30T09:08:27.326+0100] {spark_submit.py:495} INFO - |22                 |Côtes-d'Armor                  |3                         |3ème circonscription         |Complet    |88709   |17554      |19.79    |71155  |80.21    |1189  |1.34        |1.67        |645 |0.73      |0.91      |69321   |78.14    |97.42    |1        |F   |ARTHAUD|Nathalie|521 |0.59      |0.75      |
[2022-12-30T09:08:27.326+0100] {spark_submit.py:495} INFO - |75                 |Paris                          |10                        |10ème circonscription        |Complet    |69820   |15846      |22.7     |53974  |77.3     |641   |0.92        |1.19        |233 |0.33      |0.43      |53100   |76.05    |98.38    |1        |F   |ARTHAUD|Nathalie|206 |0.3       |0.39      |
[2022-12-30T09:08:27.326+0100] {spark_submit.py:495} INFO - +-------------------+-------------------------------+--------------------------+-----------------------------+-----------+--------+-----------+---------+-------+---------+------+------------+------------+----+----------+----------+--------+---------+---------+---------+----+-------+--------+----+----------+----------+
[2022-12-30T09:08:27.326+0100] {spark_submit.py:495} INFO - only showing top 20 rows
[2022-12-30T09:08:27.326+0100] {spark_submit.py:495} INFO - 
[2022-12-30T09:08:27.394+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.2.15:37791 in memory (size: 34.0 KiB, free: 434.3 MiB)
[2022-12-30T09:08:27.406+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO SparkContext: Invoking stop() from shutdown hook
[2022-12-30T09:08:27.445+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO SparkUI: Stopped Spark web UI at http://10.0.2.15:4041
[2022-12-30T09:08:27.460+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2022-12-30T09:08:27.476+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO MemoryStore: MemoryStore cleared
[2022-12-30T09:08:27.477+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO BlockManager: BlockManager stopped
[2022-12-30T09:08:27.488+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO BlockManagerMaster: BlockManagerMaster stopped
[2022-12-30T09:08:27.493+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2022-12-30T09:08:27.502+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO SparkContext: Successfully stopped SparkContext
[2022-12-30T09:08:27.502+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO ShutdownHookManager: Shutdown hook called
[2022-12-30T09:08:27.502+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-fbadadb4-7371-433f-b10f-b688f0ff0a7a
[2022-12-30T09:08:27.504+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-fbadadb4-7371-433f-b10f-b688f0ff0a7a/pyspark-3e23c413-a4a3-4e31-8977-d4c1d8d3aab4
[2022-12-30T09:08:27.506+0100] {spark_submit.py:495} INFO - 22/12/30 09:08:27 INFO ShutdownHookManager: Deleting directory /tmp/spark-8b113170-a533-4ffe-a20c-68d145a34b79
[2022-12-30T09:08:27.569+0100] {taskinstance.py:1322} INFO - Marking task as SUCCESS. dag_id=spark_airflow_project, task_id=spark_job_process, execution_date=20221230T070000, start_date=20221230T080750, end_date=20221230T080827
[2022-12-30T09:08:27.583+0100] {local_task_job.py:159} INFO - Task exited with return code 0
[2022-12-30T09:08:27.597+0100] {taskinstance.py:2582} INFO - 1 downstream tasks scheduled from follow-on schedule check
